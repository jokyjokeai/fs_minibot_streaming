#!/usr/bin/env python3
"""
Script de simulation de matching - Test 100 inputs al√©atoires

Teste le ObjectionMatcher avec des mots, phrases et expressions
vari√©s pour analyser le comportement du matching.

Usage:
    python test_matching_simulation.py
    python test_matching_simulation.py --theme objections_finance
    python test_matching_simulation.py --mode random  # Mode g√©n√©ration al√©atoire
    python test_matching_simulation.py --mode categorized  # Mode cat√©goris√© (d√©faut)
"""

import sys
import os
import random
import argparse
import requests
import json
from collections import defaultdict

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from system.objection_matcher import ObjectionMatcher

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# OLLAMA INTEGRATION - G√©n√©ration via LLM
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

OLLAMA_URL = "http://localhost:11434/api/generate"
OLLAMA_MODEL = "mistral:7b"

def generate_with_ollama(prompt: str, max_tokens: int = 100, verbose: bool = False) -> str:
    """G√©n√®re du texte avec Ollama/Mistral."""
    if verbose:
        print(f"\n{'='*60}")
        print(f"üì§ PROMPT ENVOY√â √Ä OLLAMA:")
        print(f"{'='*60}")
        print(prompt)
        print(f"{'='*60}")
        print(f"‚öôÔ∏è  max_tokens={max_tokens}, temperature=0.9")

    try:
        response = requests.post(
            OLLAMA_URL,
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "num_predict": max_tokens,
                    "temperature": 0.9
                }
            },
            timeout=30
        )
        if verbose:
            print(f"üì• Status: {response.status_code}")

        if response.status_code == 200:
            result = response.json().get("response", "").strip()
            if verbose:
                print(f"\nüì• R√âPONSE BRUTE OLLAMA:")
                print(f"{'‚îÄ'*60}")
                print(result)
                print(f"{'‚îÄ'*60}")
            return result
        else:
            if verbose:
                print(f"‚ùå Erreur HTTP: {response.status_code}")
                print(f"   {response.text[:200]}")
    except Exception as e:
        if verbose:
            print(f"‚ùå Exception: {type(e).__name__}: {e}")
    return ""


def clean_ollama_line(line: str) -> str:
    """Nettoie une ligne g√©n√©r√©e par Ollama (enl√®ve num√©rotation, tirets, etc.)"""
    import re
    line = line.strip()
    # Enlever num√©rotation: "1.", "1)", "1-", "- ", "* "
    line = re.sub(r'^[\d]+[\.\)\-\s]+', '', line)
    line = re.sub(r'^[\-\*]\s+', '', line)
    # Enlever guillemets
    line = line.strip('"\'')
    return line.strip()


def generate_ollama_corpus(count_per_category: int = 15, verbose: bool = False) -> list:
    """G√©n√®re un corpus de test complet avec Ollama."""

    corpus = []

    print("ü§ñ G√©n√©ration du corpus avec Ollama/Mistral...")
    if verbose:
        print(f"   Objectif: {count_per_category} items par cat√©gorie")
        print(f"   Model: {OLLAMA_MODEL}")
        print(f"   URL: {OLLAMA_URL}")

    # 1. Mots simples (1 mot)
    prompt = f"""G√©n√®re {count_per_category} mots fran√ßais simples qu'une personne pourrait dire au t√©l√©phone.
M√©lange: r√©ponses (oui, non), questions (quoi, comment), moments (matin, lundi), mots al√©atoires.
Format: un mot par ligne, sans num√©rotation."""

    result = generate_with_ollama(prompt, 200, verbose)
    if verbose:
        print(f"\nüîç PARSING 1_MOT:")
    words = []
    for w in result.split('\n'):
        cleaned = clean_ollama_line(w)
        word_count = len(cleaned.split()) if cleaned else 0
        if cleaned and word_count == 1:
            words.append(cleaned)
            if verbose:
                print(f"   ‚úÖ '{cleaned}' ({word_count} mot)")
        elif cleaned and verbose:
            print(f"   ‚ùå '{cleaned}' ({word_count} mots) - rejet√©")
    words = words[:count_per_category]
    for w in words:
        corpus.append((w, "1_MOT"))
    print(f"  1_MOT: {len(words)} g√©n√©r√©s")

    # 2. Expressions courtes (2-3 mots)
    prompt = f"""G√©n√®re exactement {count_per_category} expressions fran√ßaises de 2 ou 3 mots maximum.
Exemples: "c'est bon", "pas maintenant", "non merci", "d'accord", "trop cher", "le matin", "pas confiance"
IMPORTANT: chaque expression doit faire 2 ou 3 mots UNIQUEMENT.
Format: une expression par ligne, sans explication."""

    result = generate_with_ollama(prompt, 300, verbose)
    if verbose:
        print(f"\nüîç PARSING 2-3_MOTS:")
    exprs = []
    for e in result.split('\n'):
        cleaned = clean_ollama_line(e)
        word_count = len(cleaned.split()) if cleaned else 0
        if cleaned and 1 < word_count <= 4:
            exprs.append(cleaned)
            if verbose:
                print(f"   ‚úÖ '{cleaned}' ({word_count} mots)")
        elif cleaned and verbose:
            print(f"   ‚ùå '{cleaned}' ({word_count} mots) - rejet√©")
    exprs = exprs[:count_per_category]
    for e in exprs:
        corpus.append((e, "2-3_MOTS"))
    print(f"  2-3_MOTS: {len(exprs)} g√©n√©r√©s")

    # 3. Phrases moyennes (4-6 mots)
    prompt = f"""G√©n√®re {count_per_category} phrases fran√ßaises de 4 √† 6 mots qu'on dit au t√©l√©phone.
Exemples: "je suis pas int√©ress√©", "rappelez-moi plus tard", "c'est trop cher pour moi"
Format: une phrase par ligne."""

    result = generate_with_ollama(prompt, 400, verbose)
    if verbose:
        print(f"\nüîç PARSING 4-6_MOTS:")
    phrases = []
    for p in result.split('\n'):
        cleaned = clean_ollama_line(p)
        word_count = len(cleaned.split()) if cleaned else 0
        if cleaned and 3 < word_count <= 6:
            phrases.append(cleaned)
            if verbose:
                print(f"   ‚úÖ '{cleaned}' ({word_count} mots)")
        elif cleaned and verbose:
            print(f"   ‚ùå '{cleaned}' ({word_count} mots) - rejet√©")
    phrases = phrases[:count_per_category]
    for p in phrases:
        corpus.append((p, "4-6_MOTS"))
    print(f"  4-6_MOTS: {len(phrases)} g√©n√©r√©s")

    # 4. Phrases longues (7-10 mots)
    prompt = f"""G√©n√®re exactement {count_per_category} phrases fran√ßaises de 7 √† 10 mots.
Contexte: r√©ponses d'un client √† un appel commercial.
Exemples: "je pr√©f√®re le matin vers dix heures si possible", "je dois d'abord en parler avec ma femme"
IMPORTANT: chaque phrase doit contenir entre 7 et 10 mots.
Format: une phrase par ligne, sans explication."""

    result = generate_with_ollama(prompt, 600, verbose)
    if verbose:
        print(f"\nüîç PARSING 7-10_MOTS:")
    phrases = []
    for p in result.split('\n'):
        cleaned = clean_ollama_line(p)
        word_count = len(cleaned.split()) if cleaned else 0
        if cleaned and 5 < word_count <= 12:
            phrases.append(cleaned)
            if verbose:
                print(f"   ‚úÖ '{cleaned}' ({word_count} mots)")
        elif cleaned and verbose:
            print(f"   ‚ùå '{cleaned}' ({word_count} mots) - rejet√©")
    phrases = phrases[:count_per_category]
    for p in phrases:
        corpus.append((p, "7-10_MOTS"))
    print(f"  7-10_MOTS: {len(phrases)} g√©n√©r√©s")

    # 5. Phrases tr√®s longues (11+ mots)
    prompt = f"""G√©n√®re {count_per_category} phrases fran√ßaises longues (11+ mots) qu'on dit au t√©l√©phone.
Contexte: r√©ponses d√©taill√©es √† un d√©marcheur.
Exemples: "oui √ßa m'int√©resse beaucoup j'aimerais en savoir plus sur votre offre"
Format: une phrase par ligne."""

    result = generate_with_ollama(prompt, 600, verbose)
    if verbose:
        print(f"\nüîç PARSING 11+_MOTS:")
    phrases = []
    for p in result.split('\n'):
        cleaned = clean_ollama_line(p)
        word_count = len(cleaned.split()) if cleaned else 0
        if cleaned and word_count >= 11:
            phrases.append(cleaned)
            if verbose:
                print(f"   ‚úÖ '{cleaned[:50]}...' ({word_count} mots)")
        elif cleaned and verbose:
            print(f"   ‚ùå '{cleaned[:50]}...' ({word_count} mots) - rejet√©")
    phrases = phrases[:count_per_category]
    for p in phrases:
        corpus.append((p, "11+_MOTS"))
    print(f"  11+_MOTS: {len(phrases)} g√©n√©r√©s")

    # 6. Random/hors sujet
    prompt = f"""G√©n√®re {count_per_category + 10} phrases ou mots fran√ßais compl√®tement hors sujet (pas li√©s au t√©l√©phone).
Exemples: "pizza", "le chat dort", "il fait beau aujourd'hui", "j'aime la musique"
Inclus aussi du bruit: "euh euh", "bla bla", "123"
Format: un par ligne."""

    result = generate_with_ollama(prompt, 400, verbose)
    if verbose:
        print(f"\nüîç PARSING RANDOM:")
    randoms = []
    for r in result.split('\n'):
        cleaned = clean_ollama_line(r)
        if cleaned:
            randoms.append(cleaned)
            if verbose:
                print(f"   ‚úÖ '{cleaned}'")
    randoms = randoms[:count_per_category + 10]
    for r in randoms:
        corpus.append((r, "RANDOM"))
    print(f"  RANDOM: {len(randoms)} g√©n√©r√©s")

    print(f"‚úÖ Corpus total: {len(corpus)} items")
    return corpus

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CORPUS DE TEST - 100+ inputs vari√©s
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Affirm variations
AFFIRM_INPUTS = [
    "oui", "ouais", "ok", "d'accord", "bien s√ªr", "absolument",
    "oui oui", "ah oui", "oui bien s√ªr", "oui pourquoi pas",
    "oui c'est bon", "ok √ßa marche", "√ßa me va", "parfait",
    "entendu", "tr√®s bien", "c'est not√©", "je veux bien",
    "oui allez-y", "oui je vous √©coute", "allez-y",
]

# Deny variations
DENY_INPUTS = [
    "non", "non merci", "pas int√©ress√©", "√ßa m'int√©resse pas",
    "non pas du tout", "absolument pas", "certainement pas",
    "je ne suis pas int√©ress√©", "√ßa ne m'int√©resse pas",
    "non vraiment pas", "pas pour moi", "non c'est bon",
]

# Time expressions (should map to "time" intent)
TIME_INPUTS = [
    "matin", "le matin", "demain matin", "ce matin",
    "apr√®s-midi", "cet apr√®s-midi", "l'apr√®s-midi",
    "soir", "ce soir", "demain soir", "en soir√©e",
    "lundi", "mardi", "mercredi", "jeudi", "vendredi",
    "la semaine prochaine", "cette semaine", "demain",
    "plut√¥t le matin", "plut√¥t le soir", "en fin de journ√©e",
]

# Unsure expressions
UNSURE_INPUTS = [
    "je sais pas", "sais pas", "je ne sais pas",
    "pas s√ªr", "je suis pas s√ªr", "incertain",
    "euh", "hum", "hmm", "ben", "bah",
    "aucune id√©e", "chais pas", "jsp",
]

# Objections (should trigger objection responses)
OBJECTION_INPUTS = [
    "c'est trop cher", "trop cher", "pas le budget",
    "j'ai pas le temps", "pas le temps", "je suis occup√©",
    "rappeler plus tard", "rappelez plus tard", "pas maintenant",
    "j'ai d√©j√†", "j'en ai d√©j√† un", "j'ai d√©j√† une banque",
    "c'est une arnaque", "arnaque", "vous √™tes des arnaqueurs",
    "je dois r√©fl√©chir", "faut que je r√©fl√©chisse",
    "je dois en parler", "faut que j'en parle √† ma femme",
    "envoyez-moi un mail", "par email", "documentation",
]

# FAQ questions
FAQ_INPUTS = [
    "c'est quoi exactement", "c'est quoi votre offre",
    "comment √ßa marche", "expliquez-moi", "vous faites quoi",
    "c'est qui", "vous √™tes qui", "quelle entreprise",
]

# Insults (should trigger immediate hangup)
INSULT_INPUTS = [
    "connard", "encul√©", "va te faire foutre",
    "arr√™tez de m'appeler", "retirez-moi de votre liste",
    "stop", "bloctel", "je vais porter plainte",
]

# Random/noise inputs (should be NOT_UNDERSTOOD or low score matches)
NOISE_INPUTS = [
    "la m√©t√©o", "il fait beau", "quoi de neuf",
    "allo", "all√¥", "pardon", "quoi", "comment",
    "je comprends pas", "r√©p√©tez", "vous dites",
    "attends", "une seconde", "deux minutes",
    "bonjour", "au revoir", "bonne journ√©e",
    "merci", "s'il vous pla√Æt", "excusez-moi",
    "c'est possible", "peut-√™tre", "on verra",
    "pourquoi", "quand", "o√π", "qui", "combien",
    "le chat", "la voiture", "le travail", "les enfants",
    "pizza", "caf√©", "vacances", "weekend",
]

# Edge cases - potential false positives
EDGE_CASES = [
    "je suis occup√©",  # Could be deny or objection
    "oui mais non",  # Mixed signal
    "non mais oui",  # Mixed signal
    "oui peut-√™tre",  # Affirm + unsure
    "c'est pas cher",  # Contains "cher" but negated
    "j'ai le temps demain",  # Contains time words
    "matin et soir",  # Multiple time words
    "je suis int√©ress√© mais",  # Partial affirm
    "non enfin oui",  # Contradiction
    "ui",  # Partial "oui" - should NOT match
    "ou",  # Partial "oui" - should NOT match
    "no",  # Partial "non" - should NOT match
    "d'acc",  # Partial "d'accord"
    "ok ok ok",  # Repetition
]


def run_simulation(theme: str = "objections_finance", verbose: bool = False, num_tests: int = 100):
    """Run matching simulation on random inputs."""

    print("=" * 70)
    print("üß™ SIMULATION MATCHING - ObjectionMatcher")
    print("=" * 70)
    print(f"Theme: {theme}")
    print(f"Tests: {num_tests}")
    print(f"Verbose: {verbose}")
    print("=" * 70)
    print()

    # Load matcher
    matcher = ObjectionMatcher.load_objections_for_theme(theme)
    if not matcher:
        print("‚ùå Erreur: Impossible de charger le matcher")
        return

    print(f"‚úÖ Matcher charg√©: {len(matcher.objections)} entries, {len(matcher.keyword_lookup)} keywords")
    print()

    # Build test corpus with expected results
    test_corpus = []

    # Add categorized inputs with expected intent
    for inp in AFFIRM_INPUTS:
        test_corpus.append((inp, "affirm"))
    for inp in DENY_INPUTS:
        test_corpus.append((inp, "deny"))
    for inp in TIME_INPUTS:
        test_corpus.append((inp, "time"))
    for inp in UNSURE_INPUTS:
        test_corpus.append((inp, "unsure"))
    for inp in OBJECTION_INPUTS:
        test_corpus.append((inp, "objection"))
    for inp in FAQ_INPUTS:
        test_corpus.append((inp, "question"))
    for inp in INSULT_INPUTS:
        test_corpus.append((inp, "insult"))
    for inp in NOISE_INPUTS:
        test_corpus.append((inp, "noise"))
    for inp in EDGE_CASES:
        test_corpus.append((inp, "edge"))

    # Shuffle and take num_tests
    random.shuffle(test_corpus)
    test_corpus = test_corpus[:num_tests]

    # Statistics
    stats = defaultdict(lambda: {"total": 0, "correct": 0, "wrong": 0})
    results = []

    print("‚îÄ" * 70)
    print("R√âSULTATS DES TESTS")
    print("‚îÄ" * 70)

    for i, (input_text, expected_category) in enumerate(test_corpus, 1):
        # Run matching (silent mode to avoid flooding logs)
        result = matcher.find_best_match(input_text, min_score=0.70, silent=True)

        if result:
            detected_intent = result.get("entry_type", "objection")
            score = result["score"]
            keyword = result.get("matched_keyword", "")

            # Map entry_type to intent category
            if detected_intent in ["affirm", "deny", "insult", "time", "unsure"]:
                detected_category = detected_intent
            elif detected_intent == "faq":
                detected_category = "question"
            else:
                detected_category = "objection"
        else:
            detected_intent = "none"
            detected_category = "not_understood"
            score = 0.0
            keyword = ""

        # Determine if correct
        is_correct = False
        if expected_category == "noise":
            # Noise should be not_understood OR low score
            is_correct = detected_category == "not_understood" or score < 0.5
        elif expected_category == "edge":
            # Edge cases - just log, don't count as wrong
            is_correct = True
        else:
            is_correct = detected_category == expected_category

        # Update stats
        stats[expected_category]["total"] += 1
        if is_correct:
            stats[expected_category]["correct"] += 1
        else:
            stats[expected_category]["wrong"] += 1

        # Format result
        status = "‚úÖ" if is_correct else "‚ùå"

        if verbose or not is_correct:
            print(f"{status} [{i:3d}] '{input_text}'")
            print(f"       Expected: {expected_category:15} | Got: {detected_category} (score={score:.2f}, kw='{keyword}')")
            if not is_correct:
                print(f"       ‚ö†Ô∏è  MISMATCH!")
            print()

        results.append({
            "input": input_text,
            "expected": expected_category,
            "detected": detected_category,
            "score": score,
            "keyword": keyword,
            "correct": is_correct
        })

    # Summary
    print()
    print("=" * 70)
    print("üìä R√âSUM√â STATISTIQUES")
    print("=" * 70)

    total_correct = sum(s["correct"] for s in stats.values())
    total_tests = sum(s["total"] for s in stats.values())

    print(f"\n{'Cat√©gorie':<15} {'Total':>8} {'Correct':>8} {'Wrong':>8} {'Accuracy':>10}")
    print("-" * 50)

    for category in sorted(stats.keys()):
        s = stats[category]
        accuracy = (s["correct"] / s["total"] * 100) if s["total"] > 0 else 0
        marker = "‚úÖ" if accuracy >= 90 else "‚ö†Ô∏è" if accuracy >= 70 else "‚ùå"
        print(f"{category:<15} {s['total']:>8} {s['correct']:>8} {s['wrong']:>8} {accuracy:>8.1f}% {marker}")

    print("-" * 50)
    overall_accuracy = (total_correct / total_tests * 100) if total_tests > 0 else 0
    print(f"{'TOTAL':<15} {total_tests:>8} {total_correct:>8} {total_tests - total_correct:>8} {overall_accuracy:>8.1f}%")

    # List failures
    failures = [r for r in results if not r["correct"] and r["expected"] != "edge"]
    if failures:
        print()
        print("=" * 70)
        print(f"‚ùå √âCHECS D√âTAILL√âS ({len(failures)})")
        print("=" * 70)
        for f in failures:
            print(f"\n  Input: '{f['input']}'")
            print(f"  Expected: {f['expected']}")
            print(f"  Detected: {f['detected']} (score={f['score']:.2f}, keyword='{f['keyword']}')")

    print()
    print("=" * 70)
    if overall_accuracy >= 95:
        print("üèÜ EXCELLENT! Accuracy >= 95%")
    elif overall_accuracy >= 85:
        print("‚úÖ BON. Accuracy >= 85%")
    elif overall_accuracy >= 70:
        print("‚ö†Ô∏è  MOYEN. Accuracy >= 70% - Am√©lioration recommand√©e")
    else:
        print("‚ùå PROBL√àME. Accuracy < 70% - R√©vision n√©cessaire")
    print("=" * 70)

    return results


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MODE RANDOM - G√©n√©ration al√©atoire de phrases
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Vocabulaire pour g√©n√©ration al√©atoire
VOCAB_SUJETS = ["je", "on", "nous", "vous", "c'est", "√ßa", "il", "elle", "ils"]
VOCAB_VERBES = ["suis", "veux", "peux", "dois", "vais", "ai", "fais", "comprends", "sais", "pr√©f√®re", "attends", "rappelle"]
VOCAB_NEGATIONS = ["pas", "plus", "jamais", "vraiment pas", "absolument pas"]
VOCAB_ADVERBES = ["maintenant", "demain", "plus tard", "bient√¥t", "peut-√™tre", "plut√¥t", "vraiment", "absolument"]
VOCAB_OBJETS = ["temps", "argent", "int√©r√™t", "besoin", "envie", "confiance", "budget", "moment"]
VOCAB_CONTEXTE = ["au travail", "en r√©union", "en voiture", "occup√©", "disponible", "int√©ress√©", "press√©"]
VOCAB_TEMPS = ["matin", "soir", "apr√®s-midi", "lundi", "mardi", "mercredi", "jeudi", "vendredi", "semaine prochaine"]
VOCAB_FILLER = ["euh", "ben", "hum", "alors", "donc", "bon", "bah", "enfin", "voil√†"]
VOCAB_RANDOM = ["pizza", "chat", "m√©t√©o", "football", "musique", "voiture", "enfants", "travail", "vacances", "film"]

def generate_random_phrase(length_category: str) -> str:
    """G√©n√®re une phrase al√©atoire selon la cat√©gorie de longueur."""

    if length_category == "1_MOT":
        # Un seul mot al√©atoire
        choices = ["oui", "non", "quoi", "comment", "pourquoi", "merci", "pardon",
                   "matin", "soir", "demain", "jamais", "allo", "combien", "peut-√™tre"]
        choices += VOCAB_RANDOM
        return random.choice(choices)

    elif length_category == "2-3_MOTS":
        patterns = [
            lambda: f"{random.choice(['oui', 'non'])} {random.choice(['merci', 'vraiment', 'absolument'])}",
            lambda: f"{random.choice(VOCAB_SUJETS)} {random.choice(VOCAB_VERBES)}",
            lambda: f"pas {random.choice(VOCAB_OBJETS)}",
            lambda: f"c'est {random.choice(['bon', 'cher', 'possible', 'int√©ressant'])}",
            lambda: f"{random.choice(VOCAB_FILLER)} {random.choice(VOCAB_FILLER)}",
            lambda: f"le {random.choice(VOCAB_TEMPS)}",
        ]
        return random.choice(patterns)()

    elif length_category == "4-6_MOTS":
        patterns = [
            lambda: f"je {random.choice(['suis', 'ne suis'])} pas {random.choice(VOCAB_CONTEXTE)}",
            lambda: f"j'ai pas {random.choice(['le temps', 'le budget', 'confiance', 'envie'])}",
            lambda: f"c'est {random.choice(['trop cher', 'pas le moment', 'une arnaque'])} pour moi",
            lambda: f"rappelez-moi {random.choice(['plus tard', 'demain', 'la semaine prochaine'])}",
            lambda: f"{random.choice(VOCAB_FILLER)} je {random.choice(VOCAB_VERBES)} {random.choice(VOCAB_NEGATIONS)}",
            lambda: f"plut√¥t le {random.choice(VOCAB_TEMPS)} si possible",
        ]
        return random.choice(patterns)()

    elif length_category == "7-10_MOTS":
        patterns = [
            lambda: f"je pr√©f√®re le {random.choice(VOCAB_TEMPS)} vers {random.randint(8,18)} heures",
            lambda: f"je dois d'abord en parler avec {random.choice(['ma femme', 'mon mari', 'mon banquier'])}",
            lambda: f"vous pouvez m'envoyer √ßa par {random.choice(['mail', 'courrier', 'sms'])} s'il vous pla√Æt",
            lambda: f"c'est {random.choice(VOCAB_FILLER)} je suis {random.choice(VOCAB_CONTEXTE)} l√† maintenant",
            lambda: f"non {random.choice(['merci', 'vraiment'])} {random.choice(VOCAB_FILLER)} c'est pas pour moi",
            lambda: f"oui {random.choice(['pourquoi pas', '√ßa peut', '√ßa pourrait'])} m'int√©resser {random.choice(['peut-√™tre', '√©ventuellement'])}",
        ]
        return random.choice(patterns)()

    elif length_category == "11+_MOTS":
        patterns = [
            lambda: f"oui √ßa m'int√©resse beaucoup j'aimerais en savoir plus sur {random.choice(['votre offre', 'ce que vous proposez', 'les d√©tails'])}",
            lambda: f"non vraiment pas du tout √ßa ne m'int√©resse {random.choice(VOCAB_NEGATIONS)} merci {random.choice(['quand m√™me', 'au revoir', 'bonne journ√©e'])}",
            lambda: f"√©coutez je suis {random.choice(VOCAB_CONTEXTE)} l√† je ne peux {random.choice(VOCAB_NEGATIONS)} vous parler maintenant",
            lambda: f"je vais {random.choice(['y r√©fl√©chir', 'en parler', 'voir √ßa'])} et je vous rappelle quand j'aurai pris ma d√©cision",
            lambda: f"rappelez-moi plut√¥t {random.choice(['en fin de journ√©e', 'demain matin', 'la semaine prochaine'])} ce serait mieux pour moi",
            lambda: f"je ne suis pas s√ªr que √ßa corresponde √† mes {random.choice(['besoins', 'attentes', 'crit√®res'])} actuels mais pourquoi pas",
        ]
        return random.choice(patterns)()

    else:  # RANDOM - hors sujet
        patterns = [
            lambda: random.choice(VOCAB_RANDOM),
            lambda: f"le {random.choice(VOCAB_RANDOM)} est {random.choice(['bien', 'l√†', 'parti'])}",
            lambda: f"j'aime {random.choice(['beaucoup', 'bien'])} le {random.choice(VOCAB_RANDOM)}",
            lambda: f"{random.choice(['asdfgh', 'qwerty', '12345', 'bla bla'])}",
            lambda: f"{random.choice(VOCAB_FILLER)} {random.choice(VOCAB_FILLER)} {random.choice(VOCAB_FILLER)}",
        ]
        return random.choice(patterns)()


# Corpus fixe pour comparaison (optionnel)
# 15 mots simples (1 mot)
MOTS_SIMPLES = [
    "oui", "non", "quoi", "comment", "pourquoi", "merci", "pardon",
    "matin", "soir", "demain", "lundi", "jamais", "toujours", "combien", "allo"
]

# 15 expressions courtes (2-3 mots)
EXPRESSIONS_COURTES = [
    "c'est bon", "d'accord", "pas du tout", "bien s√ªr", "√ßa marche",
    "pas maintenant", "on verra", "c'est cher", "absolument pas", "non merci",
    "pas int√©ress√©", "trop cher", "je comprends", "bonne journ√©e", "√† voir"
]

# 15 phrases moyennes (4-6 mots)
PHRASES_MOYENNES = [
    "je suis pas int√©ress√©", "j'ai pas le temps", "c'est trop cher pour moi",
    "rappelez-moi plus tard", "je suis occup√© maintenant", "laissez-moi r√©fl√©chir",
    "c'est quoi exactement", "vous √™tes qui vous", "envoyez-moi un mail",
    "j'ai d√©j√† une banque", "je dois en parler", "plut√¥t le matin",
    "la semaine prochaine", "c'est une arnaque", "non vraiment pas du tout"
]

# 15 phrases longues (7-10 mots)
PHRASES_LONGUES = [
    "je pr√©f√®re le matin vers dix heures si possible",
    "je dois d'abord en parler avec ma femme",
    "vous pouvez m'envoyer √ßa par mail s'il vous pla√Æt",
    "je ne suis pas s√ªr que √ßa corresponde",
    "c'est quoi exactement votre offre je comprends pas",
    "oui la semaine prochaine √ßa me va bien",
    "plut√¥t mercredi ou jeudi en fin de matin√©e",
    "c'est pas le moment l√† je suis en r√©union",
    "bon d'accord allez-y je vous √©coute",
    "qu'est-ce que vous voulez exactement de moi",
    "je suis d√©j√† client chez vous depuis longtemps",
    "j'ai pas confiance dans ce genre de proposition",
    "arr√™tez de m'appeler j'en ai marre de vous",
    "retirez-moi de votre liste s'il vous pla√Æt",
    "c'est gentil mais j'ai d√©j√† tout ce qu'il faut"
]

# 15 phrases tr√®s longues (11+ mots)
PHRASES_TRES_LONGUES = [
    "oui √ßa m'int√©resse beaucoup j'aimerais en savoir plus sur votre offre",
    "non vraiment pas du tout √ßa ne m'int√©resse absolument pas merci quand m√™me",
    "attendez je suis en train de conduire l√† je ne peux vraiment pas parler maintenant",
    "√©coutez je suis au travail je ne peux vraiment pas vous parler l√† c'est pas possible",
    "rappelez-moi plut√¥t en fin de journ√©e apr√®s dix-huit heures ce serait mieux pour moi",
    "je dois d'abord en parler avec ma femme avant de prendre une d√©cision c'est important",
    "je ne sais pas je vais y r√©fl√©chir et je vous rappelle quand j'aurai pris ma d√©cision",
    "je vais porter plainte si vous continuez √† m'appeler comme √ßa c'est du harc√®lement",
    "vous pouvez m'envoyer toute la documentation par mail pour que je puisse regarder tranquillement",
    "je ne suis pas s√ªr que √ßa corresponde √† mes besoins actuels mais pourquoi pas en discuter",
    "c'est une arnaque votre truc j'en suis absolument certain ne me rappelez plus jamais",
    "oui pourquoi pas √ßa pourrait m'int√©resser donnez-moi plus d'informations sur ce que vous proposez",
    "non merci je ne suis vraiment pas int√©ress√© par ce type de service bonne journ√©e au revoir",
    "je pr√©f√®re attendre un peu avant de me d√©cider c'est un engagement important quand m√™me",
    "√©coutez je vais √™tre honn√™te avec vous √ßa ne m'int√©resse pas du tout mais merci d'avoir appel√©"
]

# 25 inputs random/hors sujet (mix de longueurs)
RANDOM_INPUTS = [
    # Mots simples hors sujet
    "pizza", "chat", "m√©t√©o", "football", "vacances", "caf√©", "musique",
    # Expressions hors sujet
    "il fait beau", "le train arrive", "mon chien dort",
    # Phrases moyennes hors sujet
    "j'ai mang√© une pomme ce matin", "paris est une belle ville",
    "les enfants sont √† l'√©cole aujourd'hui", "la voiture est au garage",
    # Phrases longues hors sujet
    "j'aime beaucoup la musique classique surtout le piano",
    "le film que j'ai vu hier √©tait vraiment tr√®s bien",
    "mon chien s'appelle rex et il adore jouer dans le jardin",
    # Bruit/gibberish
    "asdfghjkl", "123456", "bla bla bla", "euh ben euh", "hum hum",
    "attends attends", "une seconde", "quoi quoi quoi", "all√¥ all√¥ vous m'entendez"
]


def run_random_simulation(theme: str = "objections_finance", run_number: int = 1, collect_issues: list = None):
    """Run random generation simulation - no expected results, just analysis."""

    print("=" * 70)
    print(f"üé≤ SIMULATION RANDOM - Run #{run_number}")
    print("=" * 70)
    print(f"Theme: {theme}")
    print("=" * 70)
    print()

    # Load matcher
    matcher = ObjectionMatcher.load_objections_for_theme(theme)
    if not matcher:
        print("‚ùå Erreur: Impossible de charger le matcher")
        return

    print(f"‚úÖ Matcher charg√©: {len(matcher.objections)} entries, {len(matcher.keyword_lookup)} keywords")
    print()

    # Build test corpus: 15+15+15+15+15+25 = 100 total
    # G√âN√âRATION AL√âATOIRE - nouvelles phrases √† chaque run
    test_corpus = []

    # G√©n√©rer des phrases al√©atoires pour chaque cat√©gorie
    for _ in range(15):
        test_corpus.append((generate_random_phrase("1_MOT"), "1_MOT"))
    for _ in range(15):
        test_corpus.append((generate_random_phrase("2-3_MOTS"), "2-3_MOTS"))
    for _ in range(15):
        test_corpus.append((generate_random_phrase("4-6_MOTS"), "4-6_MOTS"))
    for _ in range(15):
        test_corpus.append((generate_random_phrase("7-10_MOTS"), "7-10_MOTS"))
    for _ in range(15):
        test_corpus.append((generate_random_phrase("11+_MOTS"), "11+_MOTS"))
    for _ in range(25):
        test_corpus.append((generate_random_phrase("RANDOM"), "RANDOM"))

    # Shuffle
    random.shuffle(test_corpus)


def run_ollama_simulation(theme: str = "objections_finance", run_number: int = 1, collect_issues: list = None, verbose: bool = False):
    """Run simulation with Ollama-generated corpus."""

    print("=" * 70)
    print(f"ü§ñ SIMULATION OLLAMA - Run #{run_number}")
    print("=" * 70)
    print(f"Theme: {theme}")
    if verbose:
        print(f"üîß MODE VERBOSE ACTIV√â - Logs ultra d√©taill√©s")
    print("=" * 70)
    print()

    # Load matcher
    matcher = ObjectionMatcher.load_objections_for_theme(theme)
    if not matcher:
        print("‚ùå Erreur: Impossible de charger le matcher")
        return

    print(f"‚úÖ Matcher charg√©: {len(matcher.objections)} entries, {len(matcher.keyword_lookup)} keywords")
    print()

    # Generate corpus with Ollama
    test_corpus = generate_ollama_corpus(count_per_category=15, verbose=verbose)

    if len(test_corpus) < 50:
        print("‚ö†Ô∏è  Corpus trop petit, utilisation du fallback...")
        # Fallback to random generation
        test_corpus = []
        for _ in range(15):
            test_corpus.append((generate_random_phrase("1_MOT"), "1_MOT"))
        for _ in range(15):
            test_corpus.append((generate_random_phrase("2-3_MOTS"), "2-3_MOTS"))
        for _ in range(15):
            test_corpus.append((generate_random_phrase("4-6_MOTS"), "4-6_MOTS"))
        for _ in range(15):
            test_corpus.append((generate_random_phrase("7-10_MOTS"), "7-10_MOTS"))
        for _ in range(15):
            test_corpus.append((generate_random_phrase("11+_MOTS"), "11+_MOTS"))
        for _ in range(25):
            test_corpus.append((generate_random_phrase("RANDOM"), "RANDOM"))

    # Shuffle
    random.shuffle(test_corpus)

    # Statistics par cat√©gorie d√©tect√©e
    detected_stats = defaultdict(int)
    score_ranges = {"high": 0, "medium": 0, "low": 0, "none": 0}
    results_by_type = defaultdict(list)

    print("‚îÄ" * 70)
    print(f"R√âSULTATS ({len(test_corpus)} tests)")
    print("‚îÄ" * 70)
    print()

    for i, (input_text, input_type) in enumerate(test_corpus, 1):
        if verbose:
            print(f"\n{'‚ïê'*70}")
            print(f"üîç TEST #{i}: '{input_text}'")
            print(f"   Type: {input_type}")
            print(f"{'‚îÄ'*70}")

        # Use silent=False when verbose for detailed matching logs
        result = matcher.find_best_match(input_text, min_score=0.70, silent=not verbose)

        if verbose:
            if result:
                print(f"   üìä R√©sultat brut: {result}")
            else:
                print(f"   üìä R√©sultat: AUCUN MATCH")

        if result:
            entry_type = result.get("entry_type", "objection")
            score = result["score"]
            keyword = result.get("matched_keyword", "")

            if entry_type in ["affirm", "deny", "insult", "time", "unsure"]:
                detected = entry_type.upper()
            elif entry_type == "faq":
                detected = "FAQ"
            else:
                detected = "OBJECTION"

            if score >= 0.9:
                score_range = "high"
                score_icon = "üü¢"
            elif score >= 0.7:
                score_range = "medium"
                score_icon = "üü°"
            else:
                score_range = "low"
                score_icon = "üü†"
        else:
            detected = "NONE"
            score = 0.0
            keyword = ""
            score_range = "none"
            score_icon = "‚ö™"

        detected_stats[detected] += 1
        score_ranges[score_range] += 1

        # Print result
        print(f"{score_icon} [{i:3d}] [{input_type:12}] '{input_text[:50]}{'...' if len(input_text) > 50 else ''}'")
        print(f"       ‚Üí {detected:10} | score={score:.2f} | kw='{keyword}'")

        # Log issues
        is_issue = False
        issue_reason = ""

        if input_type in ["1_MOT", "RANDOM"] and 0.65 <= score < 0.7:
            is_issue = True
            issue_reason = f"FUZZY_LOW_SCORE ({score:.2f})"

        if input_type == "RANDOM" and score >= 0.7:
            is_issue = True
            issue_reason = f"RANDOM_HIGH_MATCH ({score:.2f})"

        if score >= 0.5 and len(keyword) > 0:
            input_chars = set(input_text.lower().replace(" ", ""))
            kw_chars = set(keyword.lower().replace(" ", ""))
            overlap = len(input_chars & kw_chars) / max(len(input_chars), len(kw_chars)) if max(len(input_chars), len(kw_chars)) > 0 else 0
            if overlap < 0.15 and score >= 0.5:
                is_issue = True
                issue_reason = f"SEMANTIC_MISMATCH (overlap={overlap:.2f})"

        if is_issue:
            print(f"       ‚ö†Ô∏è  ISSUE: {issue_reason}")
            if collect_issues is not None:
                collect_issues.append({
                    "run": run_number,
                    "input": input_text,
                    "input_type": input_type,
                    "detected": detected,
                    "score": score,
                    "keyword": keyword,
                    "reason": issue_reason
                })

        print()

        results_by_type[input_type].append({
            "input": input_text,
            "detected": detected,
            "score": score,
            "keyword": keyword
        })

    # Summary
    print()
    print("=" * 70)
    print("üìä R√âSUM√â PAR CAT√âGORIE D√âTECT√âE")
    print("=" * 70)

    print(f"\n{'D√©tect√©':<15} {'Count':>8} {'%':>8}")
    print("-" * 35)
    for det in sorted(detected_stats.keys()):
        pct = detected_stats[det] / len(test_corpus) * 100
        print(f"{det:<15} {detected_stats[det]:>8} {pct:>7.1f}%")

    print()
    print("=" * 70)
    print("üìä R√âSUM√â PAR NIVEAU DE SCORE")
    print("=" * 70)

    print(f"\nüü¢ High (>=0.9):   {score_ranges['high']:>3}")
    print(f"üü° Medium (0.7-0.9): {score_ranges['medium']:>3}")
    print(f"üü† Low (0.65-0.7):  {score_ranges['low']:>3}")
    print(f"‚ö™ None (<0.65):    {score_ranges['none']:>3}")

    print()
    print("=" * 70)
    print("üìä ANALYSE PAR TYPE D'INPUT")
    print("=" * 70)

    for input_type in ["1_MOT", "2-3_MOTS", "4-6_MOTS", "7-10_MOTS", "11+_MOTS", "RANDOM"]:
        results = results_by_type.get(input_type, [])
        if not results:
            continue
        avg_score = sum(r["score"] for r in results) / len(results) if results else 0
        none_count = sum(1 for r in results if r["detected"] == "NONE")

        print(f"\n{input_type}:")
        print(f"  Score moyen: {avg_score:.2f}")
        print(f"  Non match√©s: {none_count}/{len(results)}")

        det_counts = defaultdict(int)
        for r in results:
            det_counts[r["detected"]] += 1
        top_det = sorted(det_counts.items(), key=lambda x: -x[1])[:3]
        print(f"  Top d√©tections: {', '.join([f'{d}({c})' for d, c in top_det])}")

    print()
    print("=" * 70)
    print("‚úÖ Simulation termin√©e")
    print("=" * 70)

    return detected_stats, score_ranges, results_by_type

    # Statistics par cat√©gorie d√©tect√©e
    detected_stats = defaultdict(int)
    score_ranges = {"high": 0, "medium": 0, "low": 0, "none": 0}
    results_by_type = defaultdict(list)

    print("‚îÄ" * 70)
    print("R√âSULTATS (100 tests)")
    print("‚îÄ" * 70)
    print()

    for i, (input_text, input_type) in enumerate(test_corpus, 1):
        result = matcher.find_best_match(input_text, min_score=0.70, silent=True)

        if result:
            entry_type = result.get("entry_type", "objection")
            score = result["score"]
            keyword = result.get("matched_keyword", "")

            # Map to category
            if entry_type in ["affirm", "deny", "insult", "time", "unsure"]:
                detected = entry_type.upper()
            elif entry_type == "faq":
                detected = "FAQ"
            else:
                detected = "OBJECTION"

            # Score range
            if score >= 0.9:
                score_range = "high"
                score_icon = "üü¢"
            elif score >= 0.7:
                score_range = "medium"
                score_icon = "üü°"
            else:
                score_range = "low"
                score_icon = "üü†"
        else:
            detected = "NONE"
            score = 0.0
            keyword = ""
            score_range = "none"
            score_icon = "‚ö™"

        detected_stats[detected] += 1
        score_ranges[score_range] += 1

        # Print result with detailed logging
        print(f"{score_icon} [{i:3d}] [{input_type:12}] '{input_text[:40]}{'...' if len(input_text) > 40 else ''}'")
        print(f"       ‚Üí {detected:10} | score={score:.2f} | kw='{keyword}' (len={len(keyword)})")

        # Log potential issues
        is_issue = False
        issue_reason = ""

        # Issue 1: Low score match on simple words (fuzzy false positive)
        if input_type in ["MOT_SIMPLE", "RANDOM"] and 0.4 <= score < 0.7:
            is_issue = True
            issue_reason = f"FUZZY_LOW_SCORE ({score:.2f})"

        # Issue 2: RANDOM input matched with high score (should be NONE)
        if input_type == "RANDOM" and score >= 0.7:
            is_issue = True
            issue_reason = f"RANDOM_HIGH_MATCH ({score:.2f})"

        # Issue 3: Semantic mismatch (keyword doesn't relate to input)
        if score >= 0.5 and len(keyword) > 0:
            # Check if keyword shares any significant chars with input
            input_chars = set(input_text.lower().replace(" ", ""))
            kw_chars = set(keyword.lower().replace(" ", ""))
            overlap = len(input_chars & kw_chars) / max(len(input_chars), len(kw_chars))
            if overlap < 0.15 and score >= 0.5:
                is_issue = True
                issue_reason = f"SEMANTIC_MISMATCH (overlap={overlap:.2f})"

        if is_issue:
            print(f"       ‚ö†Ô∏è  ISSUE: {issue_reason}")
            if collect_issues is not None:
                collect_issues.append({
                    "run": run_number,
                    "input": input_text,
                    "input_type": input_type,
                    "detected": detected,
                    "score": score,
                    "keyword": keyword,
                    "reason": issue_reason
                })

        print()

        results_by_type[input_type].append({
            "input": input_text,
            "detected": detected,
            "score": score,
            "keyword": keyword
        })

    # Summary
    print()
    print("=" * 70)
    print("üìä R√âSUM√â PAR CAT√âGORIE D√âTECT√âE")
    print("=" * 70)

    print(f"\n{'D√©tect√©':<15} {'Count':>8} {'%':>8}")
    print("-" * 35)
    for det in sorted(detected_stats.keys()):
        pct = detected_stats[det] / 100 * 100
        print(f"{det:<15} {detected_stats[det]:>8} {pct:>7.1f}%")

    print()
    print("=" * 70)
    print("üìä R√âSUM√â PAR NIVEAU DE SCORE")
    print("=" * 70)

    print(f"\nüü¢ High (>=0.9):   {score_ranges['high']:>3}")
    print(f"üü° Medium (0.7-0.9): {score_ranges['medium']:>3}")
    print(f"üü† Low (0.4-0.7):   {score_ranges['low']:>3}")
    print(f"‚ö™ None (<0.4):     {score_ranges['none']:>3}")

    # Analysis par type d'input
    print()
    print("=" * 70)
    print("üìä ANALYSE PAR TYPE D'INPUT")
    print("=" * 70)

    for input_type in ["1_MOT", "2-3_MOTS", "4-6_MOTS", "7-10_MOTS", "11+_MOTS", "RANDOM"]:
        results = results_by_type[input_type]
        avg_score = sum(r["score"] for r in results) / len(results) if results else 0
        none_count = sum(1 for r in results if r["detected"] == "NONE")

        print(f"\n{input_type}:")
        print(f"  Score moyen: {avg_score:.2f}")
        print(f"  Non match√©s: {none_count}/{len(results)}")

        # Top detections
        det_counts = defaultdict(int)
        for r in results:
            det_counts[r["detected"]] += 1
        top_det = sorted(det_counts.items(), key=lambda x: -x[1])[:3]
        print(f"  Top d√©tections: {', '.join([f'{d}({c})' for d, c in top_det])}")

    print()
    print("=" * 70)
    print("‚úÖ Simulation termin√©e")
    print("=" * 70)

    return detected_stats, score_ranges, results_by_type


def run_multiple_simulations(theme: str = "objections_finance", num_runs: int = 10):
    """Run multiple simulations and collect all issues for analysis."""

    print("=" * 70)
    print(f"üîÑ ANALYSE MULTI-RUN - {num_runs} ex√©cutions")
    print("=" * 70)
    print()

    all_issues = []

    for run in range(1, num_runs + 1):
        print(f"\n{'#' * 70}")
        print(f"# RUN {run}/{num_runs}")
        print(f"{'#' * 70}\n")

        run_random_simulation(theme=theme, run_number=run, collect_issues=all_issues)

    # Final analysis
    print("\n" + "=" * 70)
    print("üìä ANALYSE GLOBALE - TOUS LES RUNS")
    print("=" * 70)

    if not all_issues:
        print("\n‚úÖ Aucun probl√®me d√©tect√© sur les {num_runs} runs!")
        return

    # Count issues by type
    issue_counts = defaultdict(int)
    issue_by_input = defaultdict(list)
    issue_by_keyword = defaultdict(int)

    for issue in all_issues:
        reason_type = issue["reason"].split(" ")[0]
        issue_counts[reason_type] += 1
        issue_by_input[issue["input"]].append(issue)
        issue_by_keyword[issue["keyword"]] += 1

    print(f"\nüìà Total issues d√©tect√©es: {len(all_issues)}")
    print(f"   Issues par run: {len(all_issues) / num_runs:.1f}")

    print("\nüìä Issues par type:")
    print("-" * 40)
    for reason, count in sorted(issue_counts.items(), key=lambda x: -x[1]):
        print(f"   {reason}: {count}")

    print("\nüî• TOP 10 inputs probl√©matiques (r√©currents):")
    print("-" * 60)
    sorted_inputs = sorted(issue_by_input.items(), key=lambda x: -len(x[1]))[:10]
    for inp, issues in sorted_inputs:
        print(f"\n   '{inp}' ({len(issues)} occurrences)")
        # Show what it matched to
        matches = defaultdict(int)
        for iss in issues:
            matches[f"{iss['detected']}:{iss['keyword']}"] += 1
        for match, cnt in sorted(matches.items(), key=lambda x: -x[1]):
            print(f"      ‚Üí {match} (x{cnt})")

    print("\nüéØ TOP 10 keywords qui causent des faux positifs:")
    print("-" * 60)
    sorted_kw = sorted(issue_by_keyword.items(), key=lambda x: -x[1])[:10]
    for kw, count in sorted_kw:
        print(f"   '{kw}': {count} faux positifs")

    print("\n" + "=" * 70)
    print("üìù RECOMMANDATIONS:")
    print("=" * 70)

    # Generate recommendations based on issues
    recommendations = []

    # Check for common patterns
    if issue_counts.get("FUZZY_LOW_SCORE", 0) > num_runs * 5:
        recommendations.append("- Augmenter min_score de 0.4 √† 0.5 ou 0.6")

    if issue_counts.get("SEMANTIC_MISMATCH", 0) > num_runs * 3:
        recommendations.append("- Ajouter word boundary check plus strict")
        recommendations.append("- Filtrer les matches avec overlap < 0.15")

    if issue_counts.get("RANDOM_HIGH_MATCH", 0) > num_runs * 2:
        recommendations.append("- V√©rifier les keywords trop courts ou g√©n√©riques")

    # Check specific problematic keywords
    for kw, count in sorted_kw[:5]:
        if count >= num_runs * 2:
            recommendations.append(f"- R√©viser le keyword '{kw}' (trop de faux positifs)")

    if recommendations:
        for rec in recommendations:
            print(rec)
    else:
        print("- Aucune recommandation majeure")

    print("\n" + "=" * 70)


def main():
    parser = argparse.ArgumentParser(description="Test ObjectionMatcher avec inputs al√©atoires")
    parser.add_argument("--theme", default="objections_finance", help="Theme file √† charger")
    parser.add_argument("--verbose", "-v", action="store_true", help="Afficher tous les r√©sultats")
    parser.add_argument("--num", "-n", type=int, default=100, help="Nombre de tests")
    parser.add_argument("--mode", "-m", choices=["categorized", "random", "multi", "ollama"], default="random",
                       help="Mode: categorized, random, multi, ou ollama (g√©n√©ration LLM)")
    parser.add_argument("--runs", "-r", type=int, default=10, help="Nombre de runs pour mode multi")

    args = parser.parse_args()

    if args.mode == "ollama":
        run_ollama_simulation(theme=args.theme, verbose=args.verbose)
    elif args.mode == "multi":
        run_multiple_simulations(theme=args.theme, num_runs=args.runs)
    elif args.mode == "random":
        run_random_simulation(theme=args.theme)
    else:
        run_simulation(
            theme=args.theme,
            verbose=args.verbose,
            num_tests=args.num
        )


if __name__ == "__main__":
    main()
