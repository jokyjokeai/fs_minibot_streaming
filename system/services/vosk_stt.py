"""
Vosk STT Service - MiniBotPanel v3

Service de transcription audio en texte (Speech-to-Text).
AdaptÃ© de live_asr_vad.py pour FreeSWITCH.

Technologie: Vosk (offline, franÃ§ais)

FonctionnalitÃ©s:
- Transcription fichier WAV
- Transcription streaming temps rÃ©el
- Support audio 8kHz et 16kHz
- DÃ©tection fin de parole
- Confiance par transcription

Utilisation:
    from system.services.vosk_stt import VoskSTT

    stt = VoskSTT()

    # Transcription fichier
    result = stt.transcribe_file("audio.wav")
    print(result["text"], result["confidence"])

    # Transcription streaming
    recognizer = stt.create_recognizer()
    for audio_chunk in audio_stream:
        if stt.accept_waveform(recognizer, audio_chunk):
            result = stt.get_result(recognizer)
            print(result["text"])
"""

import json
import time
import wave
from pathlib import Path
from typing import Optional, Dict, Any

from system.config import config
from system.logger import get_logger

logger = get_logger(__name__)

# Import Vosk
try:
    from vosk import Model, KaldiRecognizer
    VOSK_AVAILABLE = True
    logger.info("âœ… Vosk imported successfully")
except ImportError as e:
    VOSK_AVAILABLE = False
    logger.warning(f"âš ï¸ Vosk not available: {e}")
    # Mock classes pour Ã©viter erreurs
    class Model:
        def __init__(self, path): pass
    class KaldiRecognizer:
        def __init__(self, model, rate): pass


class VoskSTT:
    """
    Service de transcription Vosk.
    Version simplifiÃ©e basÃ©e sur live_asr_vad.py
    """

    def __init__(self):
        """Initialise le service Vosk STT."""
        logger.info("Initializing VoskSTT...")

        self.model = None
        self.is_available = VOSK_AVAILABLE
        self.sample_rate = config.VOSK_SAMPLE_RATE

        if not self.is_available:
            logger.warning("ðŸš« VoskSTT not available - missing dependencies")
            return

        # Charger modÃ¨le (toujours preload pour Ã©viter latence au premier appel)
        self._load_model()

        logger.info(f"{'âœ…' if self.is_available else 'âŒ'} VoskSTT initialized")

    def _load_model(self):
        """Charge le modÃ¨le Vosk en mÃ©moire."""
        try:
            model_path = Path(config.VOSK_MODEL_PATH)

            if not model_path.exists():
                logger.error(f"Vosk model not found: {model_path}")
                self.is_available = False
                return

            logger.info(f"ðŸ§  Loading Vosk model from {model_path}")
            start_time = time.time()

            self.model = Model(str(model_path))

            load_time = time.time() - start_time
            logger.info(f"âœ… Vosk model loaded in {load_time:.2f}s")

            # Test recognizer
            test_rec = KaldiRecognizer(self.model, self.sample_rate)
            test_rec.SetWords(True)
            logger.info("âœ… Vosk test recognizer created successfully")

            self.is_available = True

        except Exception as e:
            logger.error(f"âŒ Failed to load Vosk model: {e}")
            self.is_available = False

    def create_recognizer(self, sample_rate: int = None):
        """
        CrÃ©e un recognizer Vosk pour transcription streaming.

        Args:
            sample_rate: FrÃ©quence Ã©chantillonnage (dÃ©faut: config)

        Returns:
            KaldiRecognizer instance
        """
        if not self.is_available or not self.model:
            logger.error("Vosk model not loaded")
            return None

        sample_rate = sample_rate or self.sample_rate

        try:
            recognizer = KaldiRecognizer(self.model, sample_rate)
            recognizer.SetWords(True)  # Activer timestamps mots
            return recognizer

        except Exception as e:
            logger.error(f"Failed to create recognizer: {e}")
            return None

    def accept_waveform(self, recognizer, audio_data: bytes) -> bool:
        """
        Envoie audio chunk au recognizer.

        Args:
            recognizer: KaldiRecognizer
            audio_data: Chunk audio (bytes)

        Returns:
            True si transcription complÃ¨te disponible
        """
        if not recognizer:
            return False

        try:
            return recognizer.AcceptWaveform(audio_data)
        except Exception as e:
            logger.error(f"AcceptWaveform error: {e}")
            return False

    def get_result(self, recognizer) -> Dict[str, Any]:
        """
        RÃ©cupÃ¨re rÃ©sultat transcription finale.

        Args:
            recognizer: KaldiRecognizer

        Returns:
            Dict avec text, confidence, words
        """
        if not recognizer:
            return {"text": "", "confidence": 0.0}

        try:
            result = json.loads(recognizer.Result())
            return {
                "text": result.get("text", ""),
                "confidence": result.get("confidence", 0.0),
                "words": result.get("result", [])
            }
        except Exception as e:
            logger.error(f"Get result error: {e}")
            return {"text": "", "confidence": 0.0}

    def get_partial_result(self, recognizer) -> str:
        """
        RÃ©cupÃ¨re rÃ©sultat partiel (en cours).

        Args:
            recognizer: KaldiRecognizer

        Returns:
            Texte partiel
        """
        if not recognizer:
            return ""

        try:
            result = json.loads(recognizer.PartialResult())
            return result.get("partial", "")
        except Exception as e:
            logger.error(f"Get partial result error: {e}")
            return ""

    def transcribe_file(self, audio_file: str) -> Dict[str, Any]:
        """
        Transcrit un fichier audio complet.

        Supporte MONO et STEREO (extrait automatiquement canal gauche si stereo)

        Args:
            audio_file: Chemin vers fichier WAV

        Returns:
            Dict avec text, confidence, duration
        """
        if not self.is_available or not self.model:
            return {"text": "", "confidence": 0.0, "error": "Vosk not available"}

        try:
            audio_path = Path(audio_file)
            if not audio_path.exists():
                return {"text": "", "confidence": 0.0, "error": "File not found"}

            # Ouvrir fichier WAV
            wf = wave.open(str(audio_path), "rb")

            # Si STEREO: convertir en MONO (extraire canal gauche = client)
            num_channels = wf.getnchannels()
            if num_channels == 2:
                logger.info(f"Stereo audio detected â†’ Converting to MONO (left channel only)")

                # Sauvegarder infos avant de fermer
                sample_width = wf.getsampwidth()
                frame_rate = wf.getframerate()
                num_frames = wf.getnframes()

                stereo_frames = wf.readframes(num_frames)
                wf.close()

                # Extraire canal gauche
                import struct
                import io
                num_samples = len(stereo_frames) // 4  # 4 bytes per stereo sample (2 bytes per channel)
                stereo_samples = struct.unpack(f'<{num_samples * 2}h', stereo_frames)
                left_samples = stereo_samples[::2]  # Ã‰chantillons pairs = canal gauche
                mono_frames = struct.pack(f'<{len(left_samples)}h', *left_samples)

                # CrÃ©er WAV mono en mÃ©moire
                mono_wf = io.BytesIO()
                with wave.open(mono_wf, 'wb') as mono_wav:
                    mono_wav.setnchannels(1)
                    mono_wav.setsampwidth(sample_width)
                    mono_wav.setframerate(frame_rate)
                    mono_wav.writeframes(mono_frames)

                # RÃ©ouvrir comme wave
                mono_wf.seek(0)
                wf = wave.open(mono_wf, 'rb')

            elif num_channels != 1:
                wf.close()
                return {"text": "", "confidence": 0.0, "error": f"Unsupported channels: {num_channels}"}

            sample_rate = wf.getframerate()
            if sample_rate not in [8000, 16000, 32000, 48000]:
                wf.close()
                return {"text": "", "confidence": 0.0, "error": f"Unsupported sample rate: {sample_rate}"}

            # CrÃ©er recognizer
            recognizer = self.create_recognizer(sample_rate)
            if not recognizer:
                wf.close()
                return {"text": "", "confidence": 0.0, "error": "Failed to create recognizer"}

            # Traiter par chunks
            chunk_size = 4000
            full_text = []

            start_time = time.time()

            while True:
                data = wf.readframes(chunk_size)
                if len(data) == 0:
                    break

                if recognizer.AcceptWaveform(data):
                    result = json.loads(recognizer.Result())
                    text = result.get("text", "")
                    if text:
                        full_text.append(text)

            # RÃ©sultat final
            final_result = json.loads(recognizer.FinalResult())
            text = final_result.get("text", "")
            if text:
                full_text.append(text)

            wf.close()

            duration = time.time() - start_time
            transcription = " ".join(full_text).strip()

            logger.info(f"Transcribed {audio_path.name} in {duration:.2f}s: {transcription[:100]}")

            return {
                "text": transcription,
                "confidence": final_result.get("confidence", 0.0),
                "duration": duration,
                "audio_duration": wf.getnframes() / sample_rate if wf else 0
            }

        except Exception as e:
            logger.error(f"Transcription error: {e}", exc_info=True)
            return {"text": "", "confidence": 0.0, "error": str(e)}

    def cleanup(self, recognizer):
        """
        Nettoie un recognizer.

        Args:
            recognizer: KaldiRecognizer Ã  nettoyer
        """
        # Vosk n'a pas besoin de cleanup explicite
        pass
