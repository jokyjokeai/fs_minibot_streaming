# üì¶ GUIDE D'INSTALLATION COMPLET - MiniBotPanel v3

Installation compl√®te du syst√®me de robot d'appels conversationnels avec FreeSWITCH, IA Freestyle et matching intelligent d'objections.

---

## üìã TABLE DES MATI√àRES

1. [Pr√©requis Syst√®me](#1-pr√©requis-syst√®me)
2. [Installation PostgreSQL](#2-installation-postgresql)
3. [Installation FreeSWITCH](#3-installation-freeswitch)
4. [Installation Python & D√©pendances](#4-installation-python--d√©pendances)
5. [Configuration FreeSWITCH](#5-configuration-freeswitch)
6. [Installation des Mod√®les IA](#6-installation-des-mod√®les-ia)
7. [Configuration du Projet](#7-configuration-du-projet)
8. [Initialisation de la Base de Donn√©es](#8-initialisation-de-la-base-de-donn√©es)
9. [Tests de Validation](#9-tests-de-validation)
10. [D√©marrage du Syst√®me](#10-d√©marrage-du-syst√®me)
11. [Configuration Freestyle AI](#11-configuration-freestyle-ai)
12. [Troubleshooting](#12-troubleshooting)

---

## 1. PR√âREQUIS SYST√àME

### Mat√©riel Minimum

| Composant | Minimum | Recommand√© | Pour Freestyle AI |
|-----------|---------|------------|-------------------|
| CPU | 2 cores | 4+ cores | 8+ cores |
| RAM | 4 GB | 8 GB | **12 GB** (Mistral 7B) |
| Disque | 20 GB | 50 GB SSD | 100 GB SSD |
| GPU | ‚Äî | NVIDIA (optionnel) | RTX 3060+ (acc√©l√©ration TTS) |
| R√©seau | 10 Mbps | 100 Mbps | 1 Gbps (streaming) |

**‚ö†Ô∏è Note Freestyle AI** : Le mode Freestyle n√©cessite au minimum **8 GB RAM** pour Mistral 7B ou **4 GB RAM** pour Llama 3.2 1B.

### Syst√®me d'exploitation

**Linux (recommand√©) :**
- Ubuntu 20.04 LTS / 22.04 LTS / 24.04 LTS
- Debian 11 / 12
- Rocky Linux 8 / 9

**macOS :**
- macOS 12+ (Monterey ou sup√©rieur)
- **Note :** python-ESL n√©cessite compilation manuelle

**Windows :**
- Non support√© officiellement (utiliser WSL2)

### Logiciels requis

```bash
# Ubuntu/Debian
- Python 3.11+ (3.11 recommand√©)
- PostgreSQL 14+
- FreeSWITCH 1.10+
- Git
- Build essentials
- ffmpeg
- Ollama (pour Freestyle AI)

# macOS
- Homebrew
- Python 3.11+ (via brew)
- PostgreSQL 14+ (via brew)
- FreeSWITCH (via brew ou compilation)
- Ollama (via official installer)
```

---

## 2. INSTALLATION POSTGRESQL

### Ubuntu/Debian

```bash
# 1. Ajouter repository PostgreSQL
sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -

# 2. Installer PostgreSQL
sudo apt update
sudo apt install -y postgresql-14 postgresql-contrib-14

# 3. D√©marrer le service
sudo systemctl start postgresql
sudo systemctl enable postgresql

# 4. V√©rifier le statut
sudo systemctl status postgresql
```

### macOS

```bash
# Via Homebrew
brew install postgresql@14
brew services start postgresql@14

# V√©rifier
psql --version
# Sortie attendue : psql (PostgreSQL) 14.x
```

### Cr√©er la base de donn√©es

```bash
# 1. Se connecter comme postgres
sudo -u postgres psql

# 2. Dans le shell PostgreSQL :
CREATE DATABASE minibot_freeswitch;
CREATE USER minibot WITH PASSWORD 'minibot';
GRANT ALL PRIVILEGES ON DATABASE minibot_freeswitch TO minibot;
\q

# 3. Tester la connexion
psql -h localhost -U minibot -d minibot_freeswitch
# Entrer le mot de passe : minibot
```

**‚ö†Ô∏è PRODUCTION** : Changez le mot de passe `minibot` pour un mot de passe fort !

---

## 3. INSTALLATION FREESWITCH

### Ubuntu/Debian (via packages)

```bash
# 1. Ajouter la cl√© GPG FreeSWITCH
wget -O - https://files.freeswitch.org/repo/deb/debian-release/fsstretch-archive-keyring.asc | sudo apt-key add -

# 2. Ajouter le repository
echo "deb http://files.freeswitch.org/repo/deb/debian-release/ $(lsb_release -sc) main" | sudo tee /etc/apt/sources.list.d/freeswitch.list

# 3. Installer FreeSWITCH
sudo apt update
sudo apt install -y freeswitch-meta-all

# 4. D√©marrer FreeSWITCH
sudo systemctl start freeswitch
sudo systemctl enable freeswitch

# 5. V√©rifier
sudo systemctl status freeswitch
fs_cli -x "status"
```

### macOS (via Homebrew)

```bash
# Installer FreeSWITCH
brew install freeswitch

# D√©marrer FreeSWITCH
brew services start freeswitch

# V√©rifier
fs_cli -x "status"
```

### Compilation depuis les sources (optionnel)

```bash
# 1. Cloner le repository
cd /usr/src
sudo git clone https://github.com/signalwire/freeswitch.git
cd freeswitch

# 2. Bootstrap
sudo ./bootstrap.sh -j

# 3. Configuration
sudo ./configure --prefix=/usr/local/freeswitch

# 4. Compiler
sudo make -j$(nproc)
sudo make install

# 5. Cr√©er le service systemd
sudo nano /etc/systemd/system/freeswitch.service
```

**Contenu du fichier freeswitch.service :**

```ini
[Unit]
Description=FreeSWITCH
After=network.target

[Service]
Type=forking
ExecStart=/usr/local/freeswitch/bin/freeswitch -nc -nonat
ExecReload=/usr/local/freeswitch/bin/fs_cli -x "reloadxml"
ExecStop=/usr/local/freeswitch/bin/fs_cli -x "shutdown"
Restart=on-failure
RestartSec=10
User=freeswitch
Group=freeswitch

[Install]
WantedBy=multi-user.target
```

```bash
# Activer et d√©marrer
sudo systemctl daemon-reload
sudo systemctl enable freeswitch
sudo systemctl start freeswitch
```

---

## 4. INSTALLATION PYTHON & D√âPENDANCES

### 1. Installer Python 3.11+ ou 3.11

**Ubuntu/Debian :**

```bash
sudo apt update
sudo apt install -y python3.11 python3.11-venv python3.11-dev
sudo apt install -y build-essential libffi-dev libssl-dev libsndfile1-dev
```

**macOS :**

```bash
brew install python@3.11
```

### 2. Cloner le projet

```bash
cd /opt  # Ou tout autre r√©pertoire
sudo git clone <url_du_repository> minibot_streaming
cd minibot_streaming
sudo chown -R $USER:$USER .
```

### 3. Cr√©er l'environnement virtuel

```bash
python3.11 -m venv venv
source venv/bin/activate

# V√©rifier
python --version
# Sortie : Python 3.11.x
```

### 4. Installer les d√©pendances Python

```bash
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
```

**Note :** L'installation peut prendre 10-20 minutes (t√©l√©chargement de PyTorch, Coqui TTS, transformers, etc.)

**Nouveaut√©s v3** install√©es via requirements.txt :
- `ollama` : Client Python pour Freestyle AI
- `difflib` : Matching fuzzy d'objections (int√©gr√© √† Python)
- `python-dotenv` : Gestion variables d'environnement

### 5. Installer python-ESL

**Linux :**

```bash
# Si disponible via apt
sudo apt install freeswitch-python-esl

# Ou via pip (version compatible)
pip install python-esl
```

**macOS :** (Compilation manuelle requise)

```bash
# Copier ESL.py depuis FreeSWITCH sources
cp /usr/local/freeswitch/share/freeswitch/scripts/ESL.py venv/lib/python3.11/site-packages/

# Ou compiler depuis les sources FreeSWITCH
cd /usr/local/freeswitch/libs/esl
make pymod
cp ESL.py $VIRTUAL_ENV/lib/python3.11/site-packages/
```

### 6. Installer ffmpeg

**Ubuntu/Debian :**

```bash
sudo apt install -y ffmpeg
```

**macOS :**

```bash
brew install ffmpeg
```

**V√©rifier :**

```bash
ffmpeg -version
# Sortie : ffmpeg version 4.x ou 5.x
```

---

## 5. CONFIGURATION FREESWITCH

### 1. Configuration Event Socket Layer (ESL)

√âditer `/etc/freeswitch/autoload_configs/event_socket.conf.xml` :

```xml
<configuration name="event_socket.conf" description="Socket Protocol">
  <settings>
    <param name="listen-ip" value="127.0.0.1"/>
    <param name="listen-port" value="8021"/>
    <param name="password" value="ClueCon"/>
    <param name="apply-inbound-acl" value="loopback.auto"/>
  </settings>
</configuration>
```

**‚ö†Ô∏è PRODUCTION :** Changez le mot de passe `ClueCon` !

### 2. Configuration du dialplan

Cr√©er `/etc/freeswitch/dialplan/minibot_outbound.xml` :

```xml
<?xml version="1.0" encoding="utf-8"?>
<include>
  <context name="minibot">
    <extension name="outbound_calls">
      <condition field="destination_number" expression="^(.+)$">
        <action application="set" data="continue_on_fail=true"/>
        <action application="set" data="hangup_after_bridge=true"/>
        <action application="answer"/>
        <action application="sleep" data="100"/>
        <action application="park"/>
      </condition>
    </extension>
  </context>
</include>
```

### 3. Configuration SIP Gateway

√âditer `/etc/freeswitch/sip_profiles/external/gateway1.xml` :

```xml
<include>
  <gateway name="gateway1">
    <param name="realm" value="sip.votre-provider.com"/>
    <param name="username" value="votre_username"/>
    <param name="password" value="votre_password"/>
    <param name="proxy" value="sip.votre-provider.com"/>
    <param name="register" value="true"/>
    <param name="caller-id-in-from" value="true"/>
  </gateway>
</include>
```

**Remplacez** `sip.votre-provider.com`, `username`, et `password` par vos identifiants SIP.

### 4. Red√©marrer FreeSWITCH

```bash
sudo systemctl restart freeswitch

# V√©rifier les logs
sudo tail -f /var/log/freeswitch/freeswitch.log

# Tester ESL
fs_cli
> status
> sofia status gateway gateway1
```

---

## 6. INSTALLATION DES MOD√àLES IA

### 1. Vosk (Speech-to-Text)

```bash
# Cr√©er le dossier models
mkdir -p models
cd models

# T√©l√©charger le mod√®le fran√ßais
wget https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip

# D√©compresser
unzip vosk-model-small-fr-0.22.zip
mv vosk-model-small-fr-0.22 vosk-model-fr

# V√©rifier
ls -lh vosk-model-fr/
# Doit contenir : am/, conf/, graph/, ivector/

cd ..
```

**Mod√®les alternatifs :**
- `vosk-model-fr-0.22` : Mod√®le complet (1.5 GB) - meilleure pr√©cision
- `vosk-model-small-fr-0.22` : Mod√®le l√©ger (40 MB) - plus rapide

### 2. Ollama (NLP - **NOUVEAU v3**)

**Installation Ollama :**

```bash
# Linux : Installation automatique
curl -fsSL https://ollama.com/install.sh | sh

# macOS : T√©l√©charger depuis https://ollama.com/download
# Ou via Homebrew
brew install ollama

# V√©rifier l'installation
ollama --version
```

**D√©marrer le service Ollama :**

```bash
# Linux (systemd)
sudo systemctl start ollama
sudo systemctl enable ollama

# macOS / Linux (manual)
ollama serve &
```

**T√©l√©charger les mod√®les pour Freestyle AI :**

```bash
# Option 1 : Mistral 7B (recommand√© - meilleure qualit√©)
ollama pull mistral:7b
# Taille : ~4.1 GB
# RAM requise : 8 GB minimum

# Option 2 : Llama 3.2 1B (plus rapide, moins de RAM)
ollama pull llama3.2:1b
# Taille : ~1.3 GB
# RAM requise : 2 GB minimum

# Option 3 : Llama 3.2 3B (bon compromis)
ollama pull llama3.2:3b
# Taille : ~2 GB
# RAM requise : 4 GB minimum

# V√©rifier les mod√®les install√©s
ollama list
```

**Tableau comparatif des mod√®les :**

| Mod√®le | Taille | RAM min | Qualit√© | Latence | Recommandation |
|--------|--------|---------|---------|---------|----------------|
| **mistral:7b** | 4.1 GB | 8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ~1-2s | Production |
| llama3.2:3b | 2 GB | 4 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ~0.5-1s | √âquilibr√© |
| llama3.2:1b | 1.3 GB | 2 GB | ‚≠ê‚≠ê‚≠ê | ~0.3-0.5s | Dev/Test |

**Tester Ollama :**

```bash
# Test API
curl http://localhost:11434/api/tags

# Test de g√©n√©ration
ollama run mistral:7b "Bonjour, comment allez-vous ?"
```

### 3. Coqui TTS (Text-to-Speech)

```bash
# Cr√©er le dossier cache
mkdir -p models/coqui_cache

# Les mod√®les se t√©l√©chargent automatiquement au premier lancement
# Taille : ~2 GB (XTTS v2 multilingual)
```

**Activation GPU (optionnel) :**

```bash
# Installer PyTorch avec CUDA
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

# V√©rifier GPU
python -c "import torch; print(torch.cuda.is_available())"
# Sortie : True (si GPU d√©tect√©)
```

**Mod√®les TTS disponibles :**

```bash
# Mod√®le par d√©faut : XTTS v2 (multilingual, clonage de voix)
# T√©l√©chargement automatique au premier usage

# Test manuel du TTS
python -c "
from TTS.api import TTS
tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2')
tts.tts_to_file(text='Bonjour, je suis Julie de TechCorp.', file_path='test_tts.wav', language='fr')
print('‚úÖ TTS test OK : test_tts.wav g√©n√©r√©')
"
```

### 4. V√©rifier toutes les installations

```bash
# Activer l'environnement virtuel
source venv/bin/activate

# Lancer le script de test
python test_services.py
```

**Sortie attendue :**

```
‚úÖ PostgreSQL : Connected
‚úÖ Vosk STT   : Model loaded (vosk-model-fr)
‚úÖ Coqui TTS  : Model loaded (xtts_v2)
‚úÖ Ollama NLP : Connected (mistral:7b)
‚úÖ FreeSWITCH : ESL connected (127.0.0.1:8021)
‚úÖ Objection Matcher : Loaded 153 objections
```

---

## 7. CONFIGURATION DU PROJET

### 1. Copier le fichier d'exemple

```bash
cp .env.example .env
```

### 2. √âditer le fichier `.env`

```bash
nano .env
```

**Configuration compl√®te v3 :**

```bash
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# DATABASE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
DATABASE_URL=postgresql://minibot:minibot@localhost:5432/minibot_freeswitch

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# FREESWITCH ESL
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
FREESWITCH_ESL_HOST=localhost
FREESWITCH_ESL_PORT=8021
FREESWITCH_ESL_PASSWORD=ClueCon
FREESWITCH_GATEWAY=gateway1
FREESWITCH_CALLER_ID=+33123456789  # VOTRE num√©ro
FREESWITCH_CONTEXT=minibot

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# VOSK STT (Speech-to-Text)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
VOSK_MODEL_PATH=models/vosk-model-fr
VOSK_SAMPLE_RATE=16000

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# OLLAMA NLP (Freestyle AI - NOUVEAU v3)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=mistral:7b
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=150

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# COQUI TTS (Text-to-Speech)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
COQUI_MODEL=tts_models/multilingual/multi-dataset/xtts_v2
COQUI_USE_GPU=false  # Mettre true si GPU disponible
COQUI_CACHE_DIR=models/coqui_cache

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# OBJECTION MATCHING (NOUVEAU v3)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
OBJECTION_MIN_SCORE=0.5
OBJECTION_USE_PRERECORDED=true
OBJECTION_FALLBACK_TO_FREESTYLE=true

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# FREESTYLE AI SETTINGS (NOUVEAU v3)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
FREESTYLE_MAX_TURNS=3
FREESTYLE_TIMEOUT=10
FREESTYLE_DEFAULT_PERSONALITY=professionnel

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# AMD (Answering Machine Detection)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
AMD_ENABLED=true
AMD_INITIAL_SILENCE=2500
AMD_GREETING_DURATION=1500
AMD_AFTER_GREETING_SILENCE=800
AMD_TOTAL_ANALYSIS_TIME=5000
AMD_MIN_WORD_LENGTH=100
AMD_BETWEEN_WORDS_SILENCE=50
AMD_MAXIMUM_NUMBER_OF_WORDS=3
AMD_MAXIMUM_WORD_LENGTH=5000

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# API SECURITY
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
API_PASSWORD=changez_moi_en_production_12345
API_HOST=0.0.0.0
API_PORT=8000

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# LOGGING
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
LOG_LEVEL=INFO
LOG_TO_FILE=true
LOG_ROTATION=daily
LOG_MAX_BYTES=10485760

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PERFORMANCE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
MAX_CONCURRENT_CALLS=10
CALL_QUEUE_SIZE=100
PRELOAD_MODELS=true
```

**‚ö†Ô∏è IMPORTANT - Param√®tres √† modifier :**

1. `FREESWITCH_CALLER_ID` : Remplacez par VOTRE num√©ro de t√©l√©phone
2. `API_PASSWORD` : Changez pour un mot de passe fort
3. `OLLAMA_MODEL` : Choisissez selon votre RAM disponible
4. `COQUI_USE_GPU` : Mettez `true` si GPU NVIDIA disponible
5. `OBJECTION_MIN_SCORE` : Seuil de confiance pour matching (0.5 = 50%)

### 3. Cr√©er les dossiers n√©cessaires

```bash
mkdir -p logs/{system,campaigns,calls,services,api,errors,debug}
mkdir -p audio/generated
mkdir -p voices
mkdir -p recordings
mkdir -p transcriptions
mkdir -p exports
mkdir -p models/coqui_cache
mkdir -p scenarios  # NOUVEAU v3
```

**Structure finale :**

```
minibot_streaming/
‚îú‚îÄ‚îÄ audio/
‚îÇ   ‚îî‚îÄ‚îÄ generated/
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îú‚îÄ‚îÄ system/
‚îÇ   ‚îú‚îÄ‚îÄ campaigns/
‚îÇ   ‚îú‚îÄ‚îÄ calls/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ errors/
‚îÇ   ‚îî‚îÄ‚îÄ debug/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ vosk-model-fr/
‚îÇ   ‚îî‚îÄ‚îÄ coqui_cache/
‚îú‚îÄ‚îÄ scenarios/          # ‚Üê NOUVEAU v3
‚îú‚îÄ‚îÄ voices/
‚îú‚îÄ‚îÄ recordings/
‚îú‚îÄ‚îÄ transcriptions/
‚îî‚îÄ‚îÄ exports/
```

---

## 8. INITIALISATION DE LA BASE DE DONN√âES

### 1. Cr√©er les tables

```bash
# Activer l'environnement virtuel
source venv/bin/activate

# Lancer le script d'initialisation
python setup_database.py

# V√©rifier les tables cr√©√©es
python setup_database.py --check
```

**Sortie attendue :**

```
‚úÖ Tables cr√©√©es :
   - contacts (9 colonnes)
   - campaigns (15 colonnes)
   - calls (23 colonnes)
   - call_events (4 colonnes)

‚úÖ Index cr√©√©s : 12
‚úÖ Relations : 3
```

### 2. (Optionnel) Charger des donn√©es de test

```bash
# Cr√©er 100 contacts de test
python setup_database.py --test-data

# V√©rifier
python -c "from system.database import SessionLocal; from system.models import Contact; db = SessionLocal(); print(f'Contacts: {db.query(Contact).count()}'); db.close()"
# Sortie : Contacts: 100
```

---

## 9. TESTS DE VALIDATION

### 1. Test de la base de donn√©es

```bash
python -c "
from system.database import test_connection
if test_connection():
    print('‚úÖ PostgreSQL OK')
else:
    print('‚ùå PostgreSQL ERREUR')
"
```

### 2. Test ESL FreeSWITCH

```bash
python -c "
from system.robot_freeswitch import RobotFreeSWITCH
robot = RobotFreeSWITCH()
if robot.connect():
    print('‚úÖ FreeSWITCH ESL OK')
    robot.stop()
else:
    print('‚ùå FreeSWITCH ESL ERREUR')
"
```

### 3. Test Ollama (Freestyle AI)

```bash
# Test connexion
curl http://localhost:11434/api/tags

# Test g√©n√©ration Python
python -c "
import ollama
response = ollama.chat(model='mistral:7b', messages=[
    {'role': 'user', 'content': 'Bonjour, qui √™tes-vous ?'}
])
print('‚úÖ Ollama OK')
print(f'R√©ponse : {response[\"message\"][\"content\"]}')
"
```

### 4. Test Objection Matcher (**NOUVEAU v3**)

```bash
python system/objection_matcher.py
```

**Sortie attendue :**

```
üß™ Test ObjectionMatcher - MiniBotPanel v3

Test 1: Match exact
  Input: 'Je n'ai pas le temps'
  Match: Je n'ai pas le temps
  Score: 1.00
  ‚úÖ PASS

Test 2: Variante proche
  Input: 'D√©sol√© mais j'ai vraiment pas le temps l√†'
  Match: Je n'ai pas le temps
  Score: 0.54
  ‚úÖ PASS

...

‚úÖ Tests termin√©s
```

### 5. Test des services IA

```bash
python test_services.py
```

### 6. Test de l'API

```bash
# D√©marrer l'API
uvicorn system.api.main:app --host 0.0.0.0 --port 8000 &

# Attendre 5 secondes
sleep 5

# Tester health check
curl http://localhost:8000/health

# Sortie attendue : {"status": "healthy", "components": {...}}

# Arr√™ter l'API
pkill -f uvicorn
```

---

## 10. D√âMARRAGE DU SYST√àME

### M√©thode 1 : Script automatique

```bash
# Rendre le script ex√©cutable
chmod +x start_system.sh

# D√©marrer tous les services
./start_system.sh
```

**Le script d√©marre :**
1. PostgreSQL (si non d√©marr√©)
2. FreeSWITCH (si non d√©marr√©)
3. Ollama (si non d√©marr√©) **‚Üê NOUVEAU v3**
4. API REST (FastAPI/Uvicorn)
5. Serveur WebSocket StreamingASR
6. Batch Caller (worker de queue)

### M√©thode 2 : D√©marrage manuel

```bash
# 1. Activer l'environnement virtuel
source venv/bin/activate

# 2. D√©marrer Ollama (si pas d√©j√† en service)
ollama serve &
sleep 5

# 3. D√©marrer l'API
uvicorn system.api.main:app --host 0.0.0.0 --port 8000 --reload &

# 4. V√©rifier que l'API est lanc√©e
curl http://localhost:8000/
# Sortie : {"name": "MiniBotPanel v3 API", "status": "running", ...}

# 5. Lancer un premier appel de test (optionnel)
python launch_campaign.py --interactive
```

### V√©rification du d√©marrage

```bash
# V√©rifier les processus
ps aux | grep -E "(uvicorn|python|freeswitch|ollama)"

# V√©rifier les ports
sudo netstat -tulpn | grep -E "(8000|8021|8080|11434|5432)"

# Sortie attendue :
# 8000 : API FastAPI
# 8021 : FreeSWITCH ESL
# 8080 : StreamingASR WebSocket
# 11434 : Ollama (NOUVEAU v3)
# 5432 : PostgreSQL
```

### Arr√™ter le syst√®me

```bash
./stop_system.sh
```

---

## 11. CONFIGURATION FREESTYLE AI

### 1. Cr√©er un sc√©nario avec Freestyle

```bash
# Mode interactif
python create_scenario.py --interactive
```

**Workflow de cr√©ation :**

1. **Choisir la th√©matique** (Finance, Crypto, Immobilier, Or, Vin, etc.)
2. **Choisir l'objectif de campagne** :
   - Prise de RDV
   - G√©n√©ration de lead
   - Transfert d'appel
3. **Choisir la personnalit√© de l'agent** :
   - Professionnel
   - Doux
   - Dynamique
   - Assertif
   - Expert
   - Commercial
   - Consultative
4. **Configurer les √©tapes** avec option `audio_type: "freestyle"`

**Exemple de step Freestyle :**

```json
{
  "freestyle_answer": {
    "audio_type": "freestyle",
    "voice": "julie",
    "barge_in": true,
    "timeout": 10,
    "max_turns": 3,
    "context": {
      "agent_name": "Julie",
      "company": "TechCorp",
      "product": "solution d'automatisation",
      "campaign_context": "Prospection B2B",
      "campaign_objective": "L'objectif est d'obtenir un rendez-vous",
      "agent_tone": "professionnel, courtois, pos√©, cr√©dible",
      "agent_style": "Phrases claires et structur√©es. Vouvoiement. Arguments factuels."
    },
    "intent_mapping": {
      "affirm": "question1",
      "question": "freestyle_answer",
      "deny": "objection",
      "*": "question1"
    }
  }
}
```

### 2. Tester le Freestyle AI

```bash
# Test unitaire du prompt system
python -c "
from system.robot_freeswitch import RobotFreeSWITCH
robot = RobotFreeSWITCH()

context = {
    'agent_name': 'Julie',
    'company': 'TechCorp',
    'product': 'solution IA',
    'campaign_objective': 'Prise de RDV',
    'agent_tone': 'professionnel, courtois',
    'agent_style': 'Phrases courtes. Vouvoiement.'
}

response = robot._generate_freestyle_response(
    user_input='Je ne suis pas s√ªr...',
    context=context
)

print(f'‚úÖ Freestyle response: {response}')
"
```

### 3. Charger un sc√©nario existant

```bash
# Lister les sc√©narios disponibles
ls -lh scenarios/scenario_*.json

# Utiliser un sc√©nario dans une campagne
python launch_campaign.py --interactive
# S√©lectionnez le sc√©nario dans le menu
```

### 4. Ajuster les param√®tres Freestyle

**Dans `.env` :**

```bash
# Temp√©rature (cr√©ativit√©) : 0.0 = strict, 1.0 = cr√©atif
OLLAMA_TEMPERATURE=0.7

# Nombre max de tokens par r√©ponse
OLLAMA_MAX_TOKENS=150

# Nombre max de tours Freestyle avant fallback
FREESTYLE_MAX_TURNS=3

# Timeout pour g√©n√©ration (secondes)
FREESTYLE_TIMEOUT=10
```

**Recommandations :**

| Cas d'usage | TEMPERATURE | MAX_TOKENS | MAX_TURNS |
|-------------|-------------|------------|-----------|
| Strict (script) | 0.3 | 100 | 2 |
| √âquilibr√© | 0.7 | 150 | 3 |
| Cr√©atif | 0.9 | 200 | 5 |

---

## 12. TROUBLESHOOTING

### Probl√®me : PostgreSQL ne d√©marre pas

```bash
# V√©rifier les logs
sudo journalctl -u postgresql -n 50

# R√©initialiser le cluster
sudo pg_dropcluster 14 main --stop
sudo pg_createcluster 14 main --start
```

### Probl√®me : FreeSWITCH ESL connection refused

```bash
# V√©rifier que FreeSWITCH √©coute sur 8021
sudo netstat -tulpn | grep 8021

# Si vide, v√©rifier la config ESL
sudo nano /etc/freeswitch/autoload_configs/event_socket.conf.xml

# Red√©marrer FreeSWITCH
sudo systemctl restart freeswitch
```

### Probl√®me : Vosk model not found

```bash
# V√©rifier le chemin
ls -la models/vosk-model-fr/

# Si vide, re-t√©l√©charger
cd models
wget https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip
unzip vosk-model-small-fr-0.22.zip
mv vosk-model-small-fr-0.22 vosk-model-fr
cd ..
```

### Probl√®me : Ollama not available (**NOUVEAU v3**)

```bash
# V√©rifier le service
curl http://localhost:11434/api/tags

# Si erreur, red√©marrer Ollama
pkill ollama
ollama serve &
sleep 5
ollama pull mistral:7b

# V√©rifier les logs Ollama
journalctl -u ollama -f
```

### Probl√®me : Ollama out of memory

```bash
# V√©rifier la RAM disponible
free -h

# Utiliser un mod√®le plus l√©ger
ollama pull llama3.2:1b

# Dans .env :
OLLAMA_MODEL=llama3.2:1b

# Ou limiter le contexte
OLLAMA_MAX_TOKENS=100
```

### Probl√®me : Coqui TTS fails to load

```bash
# V√©rifier la RAM disponible
free -h

# Si < 4GB, utiliser CPU uniquement
# Dans .env :
COQUI_USE_GPU=false

# R√©installer TTS
pip uninstall TTS
pip install coqui-tts==0.27.2

# Vider le cache
rm -rf models/coqui_cache/*
```

### Probl√®me : Objection Matcher ne trouve aucun match (**NOUVEAU v3**)

```bash
# V√©rifier le score minimum
# Dans .env :
OBJECTION_MIN_SCORE=0.4  # Baisser de 0.5 √† 0.4

# Tester manuellement
python -c "
from system.objections_database import ALL_OBJECTIONS
from system.objection_matcher import ObjectionMatcher

matcher = ObjectionMatcher(ALL_OBJECTIONS['standard'])
result = matcher.find_best_match('√áa co√ªte trop cher', min_score=0.4)
print(result)
"
```

### Probl√®me : Freestyle r√©pond lentement

```bash
# 1. V√©rifier le mod√®le utilis√©
ollama list

# 2. Utiliser un mod√®le plus rapide
ollama pull llama3.2:1b
# Dans .env : OLLAMA_MODEL=llama3.2:1b

# 3. R√©duire le nombre de tokens
# Dans .env : OLLAMA_MAX_TOKENS=80

# 4. V√©rifier CPU/RAM
top
htop
```

### Probl√®me : API 401 Unauthorized

```bash
# V√©rifier que vous passez le mot de passe
curl http://localhost:8000/api/campaigns \
  -H "X-API-Key: changez_moi_en_production_12345"

# Ou via query param
curl http://localhost:8000/api/campaigns?password=changez_moi_en_production_12345
```

### Probl√®me : Calls not originating

```bash
# V√©rifier les logs FreeSWITCH
sudo tail -f /var/log/freeswitch/freeswitch.log | grep -i originate

# V√©rifier la gateway SIP
fs_cli -x "sofia status gateway gateway1"

# Si DOWN, v√©rifier les credentials SIP
sudo nano /etc/freeswitch/sip_profiles/external/gateway1.xml
```

### Probl√®me : Out of memory

```bash
# V√©rifier l'utilisation m√©moire
free -h
top

# Solutions :
# 1. Utiliser Llama 3.2 1B au lieu de Mistral 7B
ollama pull llama3.2:1b
# Dans .env : OLLAMA_MODEL=llama3.2:1b

# 2. D√©sactiver le preloading des mod√®les
# Dans .env :
PRELOAD_MODELS=false
COQUI_USE_GPU=false

# 3. R√©duire le nombre d'appels simultan√©s
# Dans .env :
MAX_CONCURRENT_CALLS=5

# 4. Limiter Ollama
export OLLAMA_NUM_PARALLEL=1
export OLLAMA_MAX_LOADED_MODELS=1
```

### Probl√®me : Sc√©narios not found (**NOUVEAU v3**)

```bash
# V√©rifier le dossier scenarios
ls -lh scenarios/

# Cr√©er un sc√©nario de test
python create_scenario.py --interactive

# V√©rifier la cr√©ation
ls -lh scenarios/scenario_*.json

# Lister via launch_campaign
python launch_campaign.py --interactive
```

### Probl√®me : python-ESL import error (macOS)

```bash
# V√©rifier si ESL.py est pr√©sent
ls $VIRTUAL_ENV/lib/python3.11/site-packages/ESL.py

# Si absent, copier depuis FreeSWITCH
cp /usr/local/freeswitch/share/freeswitch/scripts/ESL.py \
   $VIRTUAL_ENV/lib/python3.11/site-packages/

# Ou compiler depuis sources
cd /usr/local/src/freeswitch/libs/esl
make pymod
cp ESL.py $VIRTUAL_ENV/lib/python3.11/site-packages/
```

---

## üéâ INSTALLATION TERMIN√âE !

Vous pouvez maintenant :

1. **Importer des contacts** :
   ```bash
   python import_contacts.py --source contacts.csv
   ```

2. **Cr√©er un sc√©nario** (avec Freestyle AI) :
   ```bash
   python create_scenario.py --interactive
   ```

3. **Lancer une campagne** :
   ```bash
   python launch_campaign.py --interactive
   ```

4. **Monitorer en temps r√©el** :
   ```bash
   python monitor_campaign.py --campaign-id 1
   ```

5. **Exporter les r√©sultats** :
   ```bash
   python export_campaign.py --campaign-id 1
   ```

---

## üìö PROCHAINES √âTAPES

- Consulter le **GUIDE_UTILISATION.md** pour apprendre √† utiliser le syst√®me
- Consulter le **BRIEF_PROJET.md** pour comprendre l'architecture
- Consulter le **README.md** pour une vue d'ensemble des nouveaut√©s v3

### Nouveaut√©s v3 √† explorer :

‚úÖ **Freestyle AI** : R√©ponses g√©n√©r√©es dynamiquement par Ollama
‚úÖ **Objection Matching** : D√©tection rapide avec fuzzy matching
‚úÖ **7 Personnalit√©s d'agent** : Professionnel, Doux, Dynamique, etc.
‚úÖ **9 Th√©matiques m√©tier** : Finance, Crypto, Immobilier, Or, Vin, etc.
‚úÖ **3 Objectifs de campagne** : RDV, Lead, Transfert d'appel
‚úÖ **Scenarios Manager** : Gestion centralis√©e dans `scenarios/`

**Support :** Consultez les logs dans `logs/` pour diagnostiquer les probl√®mes.

---

**Version du guide** : v3.0.0
**Derni√®re mise √† jour** : 2025-01-29
