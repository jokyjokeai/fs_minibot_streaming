# Architecture VAD 3 Modes - Design Document

**Date:** 2025-11-10
**Version:** 1.0
**Auteur:** Claude Code + User

## üéØ Objectif

S√©parer la d√©tection VAD en **3 modes distincts** avec des comportements optimis√©s selon le contexte :

1. **AMD Mode** : Answering Machine Detection
2. **PLAYING Mode** : Barge-in intelligent pendant que robot parle
3. **WAITING Mode** : End-of-speech detection pendant attente r√©ponse

---

## üìä Recherche Best Practices

### Sources
- Twilio AMD Documentation (2025)
- Retell AI VAD/Turn-Taking Best Practices
- Deepgram End-of-Speech Detection
- AWS Connect Outbound Campaigns Best Practices

### Param√®tres Recommand√©s (Industry Standards)

| Param√®tre | Valeur Standard | Notre Choix | Rationale |
|-----------|----------------|-------------|-----------|
| **AMD Timeout** | 4.0s (Twilio) | 3.0s | Optimis√© pour FR, plus rapide |
| **AMD Min Speech** | N/A | 0.3s | D√©tection pr√©coce |
| **Barge-in Threshold** | 2.5-3.0s | 2.5s | Filtre backchannels |
| **Backchannel Max** | N/A | 0.8s | "oui", "ok", "hum" |
| **Silence Reset** | N/A | 2.0s | Anti-accumulation |
| **End-of-Speech Silence** | 0.5-2.0s | 1.5s | Bon compromis |
| **Waiting Timeout** | 10-15s | 10.0s | Standard t√©l√©marketing |

---

## üèóÔ∏è Architecture D√©taill√©e

### **MODE 1: AMD (Answering Machine Detection)**

**Dur√©e:** 3.0s
**Fonction:** `_monitor_vad_amd(call_uuid, record_file)`

**Workflow:**
```
1. Lancer uuid_record (enregistrer 3s)
2. Thread VAD surveille fichier en continu
3. Transcrire TOUT d√®s qu'audio d√©tect√© (pas de seuil)
4. √Ä la fin des 3s:
   - Transcrire audio complet
   - NLP pour d√©tecter: HUMAN ("all√¥"), MACHINE ("messagerie"), BEEP, SILENCE
5. Retourner r√©sultat AMD
```

**Caract√©ristiques:**
- ‚úÖ Pas de seuil minimum (m√™me 0.3s transcrit)
- ‚úÖ Transcrire progressivement pendant les 3s
- ‚úÖ NLP sur transcription finale
- ‚ùå Pas de barge-in (on √©coute juste)

**Transcriptions attendues:**
- HUMAN: "all√¥ ?", "oui bonjour", "c'est qui ?"
- MACHINE: "vous √™tes sur la messagerie de...", "laissez votre message apr√®s le bip"
- BEEP: *bip* (d√©tect√© par pattern audio ou transcription vide apr√®s beep)
- SILENCE: "" (aucune transcription)

---

### **MODE 2: PLAYING_AUDIO (Barge-in intelligent)**

**Dur√©e:** Tant que robot parle
**Fonction:** `_monitor_vad_playing(call_uuid, record_file, audio_duration)`

**Workflow:**
```
1. uuid_record d√©marre EN PARALL√àLE de uuid_broadcast
2. Thread VAD surveille en continu
3. D√©tecter segments de parole:
   - Si < 0.8s: Backchannel ‚Üí Logger + transcrire, PAS de barge-in
   - Si >= 2.5s: Vraie interruption ‚Üí BARGE-IN!
4. Si barge-in:
   - Smooth delay 1.0s
   - uuid_break + uuid_record stop
   - Transcrire fichier complet
   - Retourner transcription pour NLP
5. Si pas de barge-in:
   - Audio se termine normalement
   - Supprimer recording (pas de transcription n√©cessaire)
```

**Caract√©ristiques:**
- ‚úÖ Transcrire TOUS les segments (m√™me <0.8s)
- ‚úÖ Logger backchannels pour analytics
- ‚úÖ Barge-in seulement si >= 2.5s parole continue
- ‚úÖ Reset compteur si silence >= 2.0s
- ‚úÖ Smooth delay avant interruption

**Exemples:**
```
Robot: "Bonjour, √™tes-vous int√©ress√© par..."
Client: "oui" (0.3s) ‚Üí Logger "oui", continuer
Client: "ok" (0.2s)  ‚Üí Logger "ok", continuer
Client: "ah non d√©sol√© l√† je suis occup√©" (3.2s) ‚Üí BARGE-IN + transcription compl√®te

Avec max_autonomous_turns:
‚Üí NLP d√©tecte "occup√©" = objection
‚Üí Passer √† objection_handler
```

---

### **MODE 3: WAITING_RESPONSE (End-of-speech detection)**

**Dur√©e:** 10.0s timeout
**Fonction:** `_monitor_vad_waiting(call_uuid, record_file, timeout)`

**Workflow:**
```
1. uuid_record d√©marre (pas d'audio robot)
2. Thread VAD surveille en continu
3. D√©tecter D√âBUT de parole (d√®s 0.3s)
4. Transcrire en continu pendant que client parle
5. D√©tecter FIN de parole (silence >= 1.5s)
6. Stopper recording
7. Finaliser transcription (FinalResult)
8. Retourner transcription compl√®te
9. Si timeout (10s) atteint sans parole ‚Üí retry_silence
```

**Caract√©ristiques:**
- ‚úÖ D√©tection d√©but parole d√®s 0.3s
- ‚úÖ Transcription continue (latence minimale)
- ‚úÖ Fin de parole si silence >= 1.5s
- ‚úÖ Timeout 10s si silence total
- ‚úÖ Pas de seuil minimum (toute parole comptabilis√©e)

**Exemples:**
```
Robot: "√ätes-vous int√©ress√© ?"
[silence 2s]
Client: "euh..." (d√©but d√©tect√©)
Client: "...ben en fait... oui pourquoi pas"
[silence 1.5s] (fin d√©tect√©e)
‚Üí Transcription: "euh ben en fait oui pourquoi pas"
‚Üí NLP: ACCEPT
```

---

## üîß Impl√©mentation Technique

### Nouvelles Fonctions

**1. `_monitor_vad_amd(call_uuid, record_file)` ‚Üí str**
- Input: call_uuid, record_file path
- Output: "HUMAN" | "MACHINE" | "BEEP" | "SILENCE" | "UNKNOWN"
- Dur√©e: Exactement 3.0s
- Transcription: Vosk mode fichier (transcribe_file)

**2. `_monitor_vad_playing(call_uuid, record_file, audio_duration)` ‚Üí Optional[str]**
- Input: call_uuid, record_file, dur√©e audio robot
- Output: Transcription si barge-in, None sinon
- Dur√©e: Tant que audio_duration ou barge-in
- Transcription: Segments continus + finale si barge-in

**3. `_monitor_vad_waiting(call_uuid, record_file, timeout)` ‚Üí Optional[str]**
- Input: call_uuid, record_file, timeout
- Output: Transcription client ou None si timeout
- Dur√©e: Jusqu'√† end-of-speech ou timeout
- Transcription: Continue pendant parole + finale

### Fonctions Modifi√©es

**1. `_detect_answering_machine(call_uuid)`**
```python
# AVANT: Listening initial + transcription ad-hoc
# APR√àS: Appeler _monitor_vad_amd()
record_file = start_recording()
result = self._monitor_vad_amd(call_uuid, record_file)
return result  # "HUMAN" | "MACHINE" | etc.
```

**2. `_play_audio(call_uuid, audio_file)`**
```python
# AVANT: _monitor_barge_in_vad() (ancien mode)
# APR√àS: _monitor_vad_playing()
record_file = start_recording()
vad_thread = Thread(target=self._monitor_vad_playing, args=(call_uuid, record_file, duration))
# ...check barge-in flag...
```

**3. `_listen_for_response(call_uuid, timeout)`**
```python
# AVANT: _listen_record_fallback() (enregistrement fixe)
# APR√àS: _monitor_vad_waiting()
record_file = start_recording()
transcription = self._monitor_vad_waiting(call_uuid, record_file, timeout)
return transcription
```

---

## üìà B√©n√©fices Attendus

### Performance
- ‚úÖ **AMD plus rapide:** 3s vs. 2.5s + analyse actuelle
- ‚úÖ **Latence r√©duite WAITING:** Transcription continue vs. attendre timeout
- ‚úÖ **Pas de faux positifs barge-in:** Backchannels < 0.8s ignor√©s

### UX
- ‚úÖ **Conversation plus naturelle:** Backchannels logg√©s mais pas interruptifs
- ‚úÖ **R√©activit√© am√©lior√©e:** End-of-speech 1.5s vs. 4s timeout actuel
- ‚úÖ **D√©tection AMD pr√©cise:** 3s optimal pour FR

### Analytics
- ‚úÖ **Backchannels track√©s:** "oui", "ok", "hum" logg√©s
- ‚úÖ **Meilleure visibilit√©:** 3 modes distincts = logs plus clairs

---

## üß™ Plan de Test

### Test 1: AMD Mode
```
Sc√©nario 1: HUMAN
‚Üí Client dit "all√¥ ?" √† T+0.5s
‚Üí Attendu: "HUMAN" d√©tect√©

Sc√©nario 2: MACHINE
‚Üí Messagerie: "vous √™tes sur la messagerie de..."
‚Üí Attendu: "MACHINE" d√©tect√©

Sc√©nario 3: SILENCE
‚Üí Aucun son pendant 3s
‚Üí Attendu: "SILENCE" ou "UNKNOWN"
```

### Test 2: PLAYING Mode
```
Sc√©nario 1: Backchannels
‚Üí Client dit "oui" (0.3s) puis "ok" (0.2s)
‚Üí Attendu: Logg√©, PAS de barge-in

Sc√©nario 2: Vraie interruption
‚Üí Client dit "ah non mais l√† je suis occup√©" (3s)
‚Üí Attendu: BARGE-IN apr√®s 2.5s

Sc√©nario 3: Silence entre "oui"
‚Üí Client: "oui" + pause 2.5s + "ok"
‚Üí Attendu: Compteur reset, pas de barge-in
```

### Test 3: WAITING Mode
```
Sc√©nario 1: R√©ponse imm√©diate
‚Üí Client r√©pond imm√©diatement "oui je suis int√©ress√©"
‚Üí Attendu: Transcription compl√®te

Sc√©nario 2: H√©sitation
‚Üí Client: silence 2s, puis "euh...oui"
‚Üí Attendu: Transcription "euh oui"

Sc√©nario 3: Timeout
‚Üí Client ne r√©pond pas pendant 10s
‚Üí Attendu: None ‚Üí retry_silence
```

---

## üöÄ D√©ploiement

### Phase 1: Configuration (‚úÖ FAIT)
- [x] Ajouter configs 3 modes dans config.py
- [x] Ajouter √† classe Config

### Phase 2: Impl√©mentation Core
- [ ] Cr√©er `_monitor_vad_amd()`
- [ ] Cr√©er `_monitor_vad_playing()`
- [ ] Cr√©er `_monitor_vad_waiting()`

### Phase 3: Adaptation Fonctions Existantes
- [ ] Modifier `_detect_answering_machine()`
- [ ] Modifier `_play_audio()`
- [ ] Modifier `_listen_for_response()`

### Phase 4: Tests
- [ ] Test AMD mode
- [ ] Test PLAYING mode
- [ ] Test WAITING mode
- [ ] Test end-to-end call flow

### Phase 5: Rollout
- [ ] Commit avec documentation
- [ ] Test en production
- [ ] Monitoring metrics

---

## üìù Notes Techniques

### Gestion Fichiers WAV Streaming

**Probl√®me:** uuid_record √©crit header WAV incomplet pendant streaming

**Solution actuelle (√† conserver):**
- Lecture RAW binaire
- Skip jusqu'au marker "data"
- Traiter frames incr√©mentales

**Am√©lioration MODE 3 (WAITING):**
- Utiliser Vosk streaming (AcceptWaveform) pendant enregistrement
- Pas besoin d'attendre fin fichier
- R√©duire latence transcription

### Thread Safety

Tous les modes VAD fonctionnent en threads s√©par√©s :
- Acc√®s `call_sessions[uuid]` prot√©g√© par dict Python (thread-safe)
- Flag `barge_in_detected_time` utilis√© pour synchronisation
- Cleanup dans `_handle_channel_hangup` attend 0.2s pour threads

### Compatibilit√©

Anciennes configs `BARGE_IN_*` maintenues pour compatibilit√© :
```python
BARGE_IN_DURATION_THRESHOLD = PLAYING_BARGE_IN_THRESHOLD  # Alias
```

---

## üîó R√©f√©rences

- [Twilio AMD Best Practices](https://www.twilio.com/docs/voice/answering-machine-detection-faq-best-practices)
- [Retell AI VAD vs Turn-Taking](https://www.retellai.com/blog/vad-vs-turn-taking-end-point-in-conversational-ai)
- [Deepgram End-of-Speech Detection](https://developers.deepgram.com/docs/understanding-end-of-speech-detection)
- [AWS Connect Campaign Best Practices](https://docs.aws.amazon.com/connect/latest/adminguide/campaign-best-practices.html)

---

**Status:** Architecture valid√©e, impl√©mentation en cours
