#!/usr/bin/env python3
"""
Clone Voice - MiniBotPanel v3 (Multi-Voice)

Utilitaire pour cloner des voix depuis des √©chantillons audio.

Fonctionnalit√©s:
- D√©tection automatique des dossiers de voix dans voices/
- Nettoyage audio (noisereduce + Demucs pour extraction voix)
- Conversion format optimal pour Coqui XTTS (22050Hz mono WAV)
- Traitement parall√®le multi-core (4-8√ó plus rapide que s√©quentiel)
- D√©tection automatique mode clonage (quick/standard/fine-tuning)
- Clone voix avec Coqui XTTS
- G√©n√©ration automatique TTS pour objections/FAQ

Workflow:
1. Cr√©er dossier voices/{nom_voix}/
2. Ajouter fichiers audio (10+ fichiers de 6-10 secondes recommand√©s)
3. Lancer script: python clone_voice.py
4. S√©lectionner voix √† cloner
5. Script nettoie, convertit, clone et g√©n√®re TTS

Utilisation:
    python clone_voice.py
    python clone_voice.py --voice julie
    python clone_voice.py --voice marie --theme finance
    python clone_voice.py --voice julie --skip-tts
    python clone_voice.py --voice marie --force
    python clone_voice.py --voice julie --workers 4  # Utilise 4 workers parall√®les
    python clone_voice.py --voice marie --sequential  # Mode s√©quentiel (debug)
"""

import argparse
import logging
import os
import time
from pathlib import Path
from typing import List, Tuple, Optional
import json
import multiprocessing as mp
from functools import partial

# Audio processing
try:
    import noisereduce as nr
    import soundfile as sf
    from pydub import AudioSegment
    from pydub.effects import normalize
    from pydub.silence import detect_silence
    AUDIO_PROCESSING_AVAILABLE = True
except ImportError:
    AUDIO_PROCESSING_AVAILABLE = False
    print("‚ö†Ô∏è  Audio processing libraries not available (noisereduce, soundfile, pydub)")

# Demucs et pyrnnoise d√©sactiv√©s (non n√©cessaires, noisereduce suffit)
PYRNNOISE_AVAILABLE = False
DEMUCS_AVAILABLE = False

# Progress bar
try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False
    print("‚ö†Ô∏è  tqdm not available (no progress bars)")

from system.config import config
from system.services.coqui_tts import CoquiTTS

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class VoiceCloner:
    """Gestionnaire de clonage de voix multi-voix avec nettoyage audio"""

    def __init__(self):
        """Initialise le cloner"""
        self.voices_dir = Path(config.VOICES_DIR)
        self.audio_dir = Path(config.AUDIO_DIR)
        self.tts = None

        # Cr√©er dossiers si n'existent pas
        self.voices_dir.mkdir(exist_ok=True)
        self.audio_dir.mkdir(exist_ok=True)

        logger.info("üé§ VoiceCloner initialized")

    def detect_available_voices(self) -> List[str]:
        """
        D√©tecte les dossiers de voix disponibles dans voices/

        Returns:
            Liste des noms de voix disponibles
        """
        voices = []

        if not self.voices_dir.exists():
            return voices

        for item in self.voices_dir.iterdir():
            if item.is_dir() and not item.name.startswith('.'):
                # V√©rifier s'il y a des fichiers audio dedans
                audio_files = self._find_audio_files(item)
                if audio_files:
                    voices.append(item.name)

        return sorted(voices)

    def _find_audio_files(self, directory: Path) -> List[Path]:
        """
        Trouve tous les fichiers audio dans un dossier
        Ignore les fichiers de s√©paration vocale (Vocals/Instrumental)

        Args:
            directory: Dossier √† scanner

        Returns:
            Liste de chemins vers fichiers audio (originaux seulement)
        """
        audio_extensions = ['.wav', '.mp3', '.flac', '.ogg', '.m4a', '.aac']
        audio_files = []

        # Patterns √† ignorer (fichiers g√©n√©r√©s par audio-separator, spleeter, demucs)
        ignore_patterns = [
            '(Vocals)',
            '(Instrumental)',
            '(vocals)',
            '(instrumental)',
            '_vocals.',
            '_instrumental.',
            'demucs_',
            'spleeter_output',
            'htdemucs',
            'model_mel_band_roformer'
        ]

        for ext in audio_extensions:
            for file_path in directory.glob(f'*{ext}'):
                # Ignorer si le nom contient un des patterns
                if any(pattern in file_path.name for pattern in ignore_patterns):
                    continue
                audio_files.append(file_path)

        return sorted(audio_files)

    def clean_audio_file(self, input_path: Path, output_path: Path) -> bool:
        """
        Nettoie un fichier audio:
        1. Extraction voix (s√©paration musique avec Demucs)
        2. R√©duction bruit de fond (noisereduce)
        3. Trim silence (d√©but/fin)
        4. Normalisation volume

        Args:
            input_path: Fichier audio source
            output_path: Fichier audio nettoy√©

        Returns:
            True si succ√®s
        """
        if not AUDIO_PROCESSING_AVAILABLE:
            logger.warning(f"‚ö†Ô∏è  Audio processing not available, copying file as-is")
            # Copie simple
            import shutil
            shutil.copy2(input_path, output_path)
            return True

        try:
            logger.info(f"  üßπ Cleaning: {input_path.name}...")

            # √âtape 1: Extraction voix avec Demucs (state-of-the-art qualit√©)
            temp_path = input_path
            if DEMUCS_AVAILABLE:
                try:
                    logger.info(f"    ‚Üí Extracting vocals (Demucs)...")

                    # Charger mod√®le Demucs (htdemucs ou htdemucs_ft)
                    model = get_model('htdemucs')
                    model.eval()

                    # Charger audio
                    import torchaudio
                    wav, sr = torchaudio.load(str(input_path))

                    # Demucs requiert stereo (2 channels) - convertir mono ‚Üí stereo si n√©cessaire
                    if wav.shape[0] == 1:
                        # Mono ‚Üí Stereo (dupliquer le canal)
                        wav = wav.repeat(2, 1)
                    elif wav.shape[0] > 2:
                        # Plus de 2 canaux ‚Üí prendre les 2 premiers
                        wav = wav[:2, :]

                    # Appliquer s√©paration
                    with torch.no_grad():
                        sources = apply_model(model, wav[None], device='cpu', shifts=1, split=True, overlap=0.25)[0]

                    # Sources: [drums, bass, other, vocals]
                    vocals = sources[3]  # Index 3 = vocals

                    # Sauvegarder vocals
                    temp_vocals = input_path.parent / f"demucs_{input_path.name}"
                    torchaudio.save(str(temp_vocals), vocals.cpu(), sr)

                    temp_path = temp_vocals
                    logger.info(f"    ‚úÖ Vocals extracted")

                except Exception as e:
                    logger.warning(f"    ‚ö†Ô∏è  Vocal extraction failed: {e}, using original")

            # √âtape 2: Charger audio
            audio_data, sample_rate = sf.read(str(temp_path))

            # √âtape 3: R√©duction bruit avec noisereduce
            logger.info(f"    ‚Üí Noise reduction...")
            reduced_noise = nr.reduce_noise(
                y=audio_data,
                sr=sample_rate,
                stationary=True,  # Bon pour bruits constants (ventilation, etc.)
                prop_decrease=0.8  # Agressivit√© r√©duction (0-1)
            )

            # Sauvegarder temporairement pour pydub
            temp_reduced = output_path.parent / f"temp_{output_path.name}"
            sf.write(str(temp_reduced), reduced_noise, sample_rate)

            # √âtape 4: Trim silence et normalisation avec pydub
            logger.info(f"    ‚Üí Trim silence & normalize...")
            audio = AudioSegment.from_file(str(temp_reduced))

            # Trim silence (d√©but et fin)
            silence_thresh = audio.dBFS - 14  # Seuil adaptatif
            nonsilent_ranges = detect_silence(
                audio,
                min_silence_len=500,  # 500ms de silence
                silence_thresh=silence_thresh,
                seek_step=10
            )

            # Inverser pour obtenir les parties non-silencieuses
            if nonsilent_ranges:
                # Prendre du d√©but du premier son √† la fin du dernier
                start_trim = nonsilent_ranges[0][1] if nonsilent_ranges else 0
                end_trim = nonsilent_ranges[-1][0] if nonsilent_ranges else len(audio)
                audio = audio[start_trim:end_trim]

            # Normalisation
            audio = normalize(audio)

            # Sauvegarder avec codec PCM explicite
            audio.export(
                str(output_path),
                format='wav',
                codec='pcm_s16le'
            )

            # Cleanup temp files
            if temp_reduced.exists():
                temp_reduced.unlink()

            # Cleanup Demucs temp file
            if DEMUCS_AVAILABLE:
                temp_vocals = input_path.parent / f"demucs_{input_path.name}"
                if temp_vocals.exists() and temp_vocals != input_path:
                    temp_vocals.unlink()

            logger.info(f"    ‚úÖ Cleaned: {output_path.name}")
            return True

        except Exception as e:
            logger.error(f"    ‚ùå Cleaning failed: {e}")
            return False

    def convert_to_optimal_format(self, input_path: Path, output_path: Path) -> bool:
        """
        Convertit audio au format optimal pour Coqui XTTS:
        - 22050 Hz (sample rate Coqui)
        - Mono
        - WAV format

        Args:
            input_path: Fichier source
            output_path: Fichier converti

        Returns:
            True si succ√®s
        """
        try:
            # Charger avec pydub
            audio = AudioSegment.from_file(str(input_path))

            # Convertir mono
            if audio.channels > 1:
                audio = audio.set_channels(1)

            # Convertir 22050 Hz
            if audio.frame_rate != 22050:
                audio = audio.set_frame_rate(22050)

            # Exporter WAV avec codec PCM explicite (compatible torchaudio)
            audio.export(
                str(output_path),
                format='wav',
                codec='pcm_s16le',  # PCM 16-bit little-endian
                parameters=["-ar", "22050", "-ac", "1"]
            )

            logger.info(f"    ‚úÖ Converted to 22050Hz mono WAV: {output_path.name}")
            return True

        except Exception as e:
            logger.error(f"    ‚ùå Conversion failed: {e}")
            return False

    def _calculate_audio_quality_score(self, audio_data, sample_rate: int, file_size: int) -> float:
        """
        Calcule un score de qualit√© audio bas√© sur plusieurs crit√®res.
        Score plus √©lev√© = meilleure qualit√© pour le clonage vocal.

        Crit√®res (inspir√©s d'ElevenLabs):
        1. SNR (Signal-to-Noise Ratio) - > 40 dB optimal
        2. Dur√©e optimale (3-15 secondes)
        3. Volume stable (peu de variations)
        4. Pas de silence prolong√©
        5. Taille fichier (corr√©lation avec qualit√©)

        Returns:
            Score de 0 √† 100
        """
        import numpy as np

        try:
            # Convertir en mono si st√©r√©o
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)

            duration = len(audio_data) / sample_rate
            score = 0.0

            # Crit√®re 1: Dur√©e optimale (3-15 secondes = meilleur)
            if 3 <= duration <= 15:
                score += 30  # Dur√©e parfaite
            elif 1 <= duration < 3:
                score += 20  # Un peu court mais OK
            elif 15 < duration <= 30:
                score += 25  # Un peu long mais OK
            elif duration > 30:
                score += 10  # Trop long
            else:
                score += 5  # Trop court

            # Crit√®re 2: SNR (Signal-to-Noise Ratio)
            # Estimer le bruit via les 10% les plus faibles en amplitude
            sorted_abs = np.sort(np.abs(audio_data))
            noise_floor = np.mean(sorted_abs[:int(len(sorted_abs) * 0.1)])
            signal_level = np.mean(np.abs(audio_data))

            if noise_floor > 0:
                snr_estimate = 20 * np.log10(signal_level / noise_floor)
                if snr_estimate > 40:
                    score += 30  # SNR excellent (comme ElevenLabs)
                elif snr_estimate > 30:
                    score += 20  # SNR bon
                elif snr_estimate > 20:
                    score += 10  # SNR acceptable
            else:
                score += 15  # Pas de bruit d√©tectable

            # Crit√®re 3: Stabilit√© du volume (faible √©cart-type = stable)
            # Calculer l'enveloppe RMS par segments de 100ms
            frame_length = int(0.1 * sample_rate)  # 100ms
            rms_values = []
            for i in range(0, len(audio_data) - frame_length, frame_length):
                frame = audio_data[i:i+frame_length]
                rms = np.sqrt(np.mean(frame**2))
                rms_values.append(rms)

            if len(rms_values) > 0:
                rms_std = np.std(rms_values)
                rms_mean = np.mean(rms_values)
                if rms_mean > 0:
                    variation_coef = rms_std / rms_mean
                    if variation_coef < 0.3:
                        score += 25  # Tr√®s stable
                    elif variation_coef < 0.5:
                        score += 15  # Stable
                    else:
                        score += 5  # Instable

            # Crit√®re 4: Pas de silence prolong√©
            silence_threshold = np.max(np.abs(audio_data)) * 0.01  # 1% du max
            silence_frames = np.sum(np.abs(audio_data) < silence_threshold)
            silence_ratio = silence_frames / len(audio_data)

            if silence_ratio < 0.1:
                score += 15  # Tr√®s peu de silence
            elif silence_ratio < 0.3:
                score += 10  # Silence acceptable
            else:
                score += 0  # Trop de silence

            return min(score, 100.0)  # Cap √† 100

        except Exception as e:
            logger.warning(f"    ‚ö†Ô∏è  Error calculating quality score: {e}")
            return 0.0

    def calculate_total_duration(self, audio_files: List[Path]) -> float:
        """
        Calcule la dur√©e totale des fichiers audio

        Args:
            audio_files: Liste de fichiers

        Returns:
            Dur√©e totale en secondes
        """
        total_duration = 0.0

        for audio_file in audio_files:
            try:
                audio = AudioSegment.from_file(str(audio_file))
                total_duration += len(audio) / 1000.0  # ms -> secondes
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Could not read {audio_file.name}: {e}")

        return total_duration

    def detect_cloning_mode(self, total_duration: float) -> Tuple[str, str]:
        """
        D√©tecte le mode de clonage optimal selon dur√©e totale

        Args:
            total_duration: Dur√©e totale en secondes

        Returns:
            Tuple (mode, description)
        """
        if total_duration < 30:
            return "quick", "‚ö†Ô∏è  Quick mode (<30s) - Qualit√© limit√©e"
        elif total_duration < 120:
            return "standard", "‚úÖ Standard mode (30s-120s) - Qualit√© recommand√©e"
        else:
            return "fine_tuning", "üåü Fine-tuning mode (>120s) - Meilleure qualit√©"

    def _process_single_file_worker(self, args: Tuple[Path, Path]) -> Optional[Path]:
        """
        Worker function pour traitement parall√®le d'un fichier audio

        Args:
            args: Tuple (raw_file, cleaned_dir)

        Returns:
            Path du fichier optimal si succ√®s, None sinon
        """
        raw_file, cleaned_dir = args

        try:
            # Chemin de sortie (plus de fichier _optimal, c'√©tait un doublon inutile)
            cleaned_file = cleaned_dir / f"{raw_file.stem}_cleaned.wav"

            # Nettoyer ET convertir au format optimal (22050Hz mono)
            if not self.clean_audio_file(raw_file, cleaned_file):
                return None

            # Convertir directement le fichier cleaned au format optimal
            if not self.convert_to_optimal_format(cleaned_file, cleaned_file):
                return None

            return cleaned_file

        except Exception as e:
            logger.error(f"    ‚ùå Error processing {raw_file.name}: {e}")
            return None

    def process_audio_batch_parallel(
        self,
        raw_audio_files: List[Path],
        cleaned_dir: Path,
        num_workers: Optional[int] = None,
        sequential: bool = False
    ) -> List[Path]:
        """
        Traite plusieurs fichiers audio en parall√®le ou s√©quentiel

        Args:
            raw_audio_files: Liste de fichiers √† traiter
            cleaned_dir: Dossier de sortie
            num_workers: Nombre de workers (None = auto-d√©tect CPU cores)
            sequential: Si True, traite en s√©quentiel (pour debug)

        Returns:
            Liste des fichiers nettoy√©s avec succ√®s
        """
        # Auto-d√©tection nombre de cores
        if num_workers is None:
            num_workers = max(1, mp.cpu_count() - 1)  # Garde 1 core libre

        # Mode s√©quentiel (backward compatibility / debug)
        if sequential:
            logger.info(f"üîÑ Processing {len(raw_audio_files)} files sequentially...")
            cleaned_files = []

            iterator = enumerate(raw_audio_files, 1)
            if TQDM_AVAILABLE:
                iterator = tqdm(iterator, total=len(raw_audio_files), desc="Processing files", unit="file")

            for i, raw_file in iterator:
                if not TQDM_AVAILABLE:
                    logger.info(f"\n[{i}/{len(raw_audio_files)}] {raw_file.name}")

                result = self._process_single_file_worker((raw_file, cleaned_dir))
                if result:
                    cleaned_files.append(result)

            return cleaned_files

        # Mode parall√®le (optimis√©)
        logger.info(f"üöÄ Processing {len(raw_audio_files)} files with {num_workers} parallel workers...")

        # Pr√©parer arguments pour workers
        args_list = [(raw_file, cleaned_dir) for raw_file in raw_audio_files]

        # Traitement parall√®le avec progress bar
        cleaned_files = []

        with mp.Pool(processes=num_workers) as pool:
            if TQDM_AVAILABLE:
                # Avec barre de progression
                results = list(tqdm(
                    pool.imap(self._process_single_file_worker, args_list),
                    total=len(args_list),
                    desc="Processing files",
                    unit="file"
                ))
            else:
                # Sans barre de progression
                results = pool.map(self._process_single_file_worker, args_list)

        # Filtrer r√©sultats valides
        cleaned_files = [f for f in results if f is not None]

        logger.info(f"‚úÖ {len(cleaned_files)}/{len(raw_audio_files)} files processed successfully")
        return cleaned_files

    def process_voice_folder(self, voice_name: str, force: bool = False, sequential: bool = False, num_workers: Optional[int] = None) -> bool:
        """
        Traite un dossier de voix complet:
        1. Nettoyage fichiers inutiles (vocals/instrumental g√©n√©r√©s)
        2. Scan fichiers audio originaux
        3. Nettoyage + conversion (parall√®le ou s√©quentiel)
        4. D√©tection mode clonage
        5. Clonage voix

        Args:
            voice_name: Nom de la voix
            force: Forcer √©crasement si existe
            sequential: Si True, traite fichiers en s√©quentiel (debug)
            num_workers: Nombre de workers parall√®les (None = auto)

        Returns:
            True si succ√®s
        """
        voice_dir = self.voices_dir / voice_name
        if not voice_dir.exists():
            logger.error(f"‚ùå Voice folder not found: {voice_dir}")
            return False

        logger.info(f"\n{'='*60}")
        logger.info(f"üé§ Processing voice: {voice_name}")
        logger.info(f"{'='*60}")

        # Nettoyer les fichiers inutiles AVANT traitement (vocals/instrumental g√©n√©r√©s)
        self._cleanup_generated_files(voice_dir)

        # Trouver fichiers audio
        raw_audio_files = self._find_audio_files(voice_dir)
        if not raw_audio_files:
            logger.error(f"‚ùå No audio files found in {voice_dir}")
            return False

        logger.info(f"üìÅ Found {len(raw_audio_files)} audio files")

        # Cr√©er dossier cleaned
        cleaned_dir = voice_dir / "cleaned"
        cleaned_dir.mkdir(exist_ok=True)

        # Nettoyer et convertir avec traitement parall√®le
        logger.info(f"\nüßπ Cleaning and converting audio files...")
        cleaned_files = self.process_audio_batch_parallel(
            raw_audio_files=raw_audio_files,
            cleaned_dir=cleaned_dir,
            num_workers=num_workers,
            sequential=sequential
        )

        if not cleaned_files:
            logger.error(f"‚ùå No files successfully processed")
            return False

        # Calculer dur√©e totale
        total_duration = self.calculate_total_duration(cleaned_files)
        logger.info(f"‚è±Ô∏è  Total duration: {total_duration:.1f}s")

        # D√©tection mode clonage
        mode, mode_desc = self.detect_cloning_mode(total_duration)
        logger.info(f"üéØ Cloning mode: {mode_desc}")

        # Initialiser Coqui TTS
        if self.tts is None:
            logger.info(f"\nü§ñ Initializing Coqui TTS...")
            self.tts = CoquiTTS()

            if not self.tts.is_available:
                logger.error("‚ùå Coqui TTS not available")
                return False

        # Cloner voix avec TOUS les fichiers valides pour embeddings moyenn√©s
        # XTTS va extraire les embeddings de chaque fichier et les moyenner
        logger.info(f"\nüé§ Cloning voice '{voice_name}' with averaged embeddings...")

        # Analyser et scorer TOUS les fichiers pour s√©lectionner les meilleurs
        logger.info(f"\nüîç Analyzing audio quality to select best files...")

        scored_files = []
        MIN_FILE_SIZE = 10 * 1024  # 10KB minimum

        for cleaned_file in cleaned_files:
            try:
                file_size = cleaned_file.stat().st_size
                if file_size < MIN_FILE_SIZE:
                    continue

                # Lire le fichier audio
                import soundfile as sf
                import numpy as np

                data, sr = sf.read(str(cleaned_file))

                if len(data) == 0 or sr == 0:
                    continue

                # Calculer le score de qualit√©
                score = self._calculate_audio_quality_score(data, sr, file_size)

                if score > 0:
                    scored_files.append({
                        'path': str(cleaned_file),
                        'name': cleaned_file.name,
                        'score': score,
                        'size': file_size,
                        'duration': len(data) / sr
                    })
                    logger.info(f"    üìä {cleaned_file.name}: score={score:.2f}, duration={len(data)/sr:.1f}s")

            except Exception as e:
                logger.warning(f"    ‚ö†Ô∏è  Error analyzing {cleaned_file.name}: {e}")
                continue

        if not scored_files:
            logger.error(f"‚ùå No valid audio files found")
            return False

        # Trier par score d√©croissant et s√©lectionner les 10 meilleurs
        scored_files.sort(key=lambda x: x['score'], reverse=True)

        # S√©lectionner les N meilleurs (max 10 ou tous si moins de 10)
        MAX_BEST_FILES = 10
        best_files = scored_files[:min(MAX_BEST_FILES, len(scored_files))]

        logger.info(f"\nüéØ Selected {len(best_files)} BEST files (out of {len(scored_files)} analyzed):")
        for i, f in enumerate(best_files, 1):
            logger.info(f"    {i}. {f['name']} - score: {f['score']:.2f}, duration: {f['duration']:.1f}s")

        best_file_paths = [f['path'] for f in best_files]

        # Passer les meilleurs fichiers √† clone_voice() pour moyenne des embeddings
        success = self.tts.clone_voice(best_file_paths, voice_name)

        if not success:
            logger.error(f"‚ùå Voice cloning failed")
            return False

        logger.info(f"‚úÖ Voice '{voice_name}' cloned successfully!")

        # Sauvegarder m√©tadonn√©es
        metadata = {
            "voice_name": voice_name,
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
            "num_files": len(cleaned_files),
            "total_duration_seconds": total_duration,
            "cloning_mode": mode,
            "sample_rate": 22050,
            "format": "WAV mono"
        }

        metadata_path = voice_dir / "metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

        logger.info(f"üìÑ Metadata saved: {metadata_path}")

        return True

    def _cleanup_generated_files(self, voice_dir: Path):
        """
        Nettoie les fichiers g√©n√©r√©s par audio-separator/spleeter/demucs
        Garde seulement les originaux (youtube_XXX.wav) et le dossier cleaned/

        Args:
            voice_dir: Dossier de la voix
        """
        logger.info(f"\nüßπ Cleaning up generated files...")

        # Patterns de fichiers √† supprimer
        cleanup_patterns = [
            '*_(Vocals)*.wav',
            '*_(Instrumental)*.wav',
            '*_(vocals)*.wav',
            '*_(instrumental)*.wav',
            '*_vocals.wav',
            '*_instrumental.wav',
            'demucs_*.wav',
            '*model_mel_band_roformer*.wav'
        ]

        deleted_count = 0
        for pattern in cleanup_patterns:
            for file_path in voice_dir.glob(pattern):
                try:
                    file_path.unlink()
                    deleted_count += 1
                    logger.debug(f"    Deleted: {file_path.name}")
                except Exception as e:
                    logger.warning(f"    Failed to delete {file_path.name}: {e}")

        # Supprimer dossiers temporaires
        temp_dirs = ['spleeter_output', 'separated']
        for temp_dir_name in temp_dirs:
            temp_dir = voice_dir / temp_dir_name
            if temp_dir.exists():
                try:
                    import shutil
                    shutil.rmtree(temp_dir)
                    deleted_count += 1
                    logger.debug(f"    Deleted directory: {temp_dir_name}/")
                except Exception as e:
                    logger.warning(f"    Failed to delete {temp_dir_name}/: {e}")

        if deleted_count > 0:
            logger.info(f"    ‚úÖ Cleaned {deleted_count} generated files/folders")
        else:
            logger.info(f"    ‚úÖ No cleanup needed")

    def generate_tts_for_objections(self, voice_name: str, theme: Optional[str] = None) -> bool:
        """
        G√©n√®re TTS pour toutes les objections/FAQ de la base de donn√©es

        Args:
            voice_name: Nom de la voix √† utiliser
            theme: Th√©matique sp√©cifique (None = toutes)

        Returns:
            True si succ√®s
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"üîä Generating TTS for objections/FAQ...")
        logger.info(f"{'='*60}")

        # V√©rifier que la voix est clon√©e
        voice_dir = self.voices_dir / voice_name
        if not voice_dir.exists():
            logger.error(f"‚ùå Voice '{voice_name}' not found. Clone voice first.")
            return False

        # Initialiser Coqui TTS si n√©cessaire
        if self.tts is None:
            logger.info(f"ü§ñ Initializing Coqui TTS...")
            self.tts = CoquiTTS()

            if not self.tts.is_available:
                logger.error("‚ùå Coqui TTS not available")
                return False

        # Importer objections database
        try:
            from system import objections_database
        except ImportError:
            logger.error("‚ùå Could not import objections_database")
            return False

        # Cr√©er dossier de sortie audio/tts/{voice_name}/
        output_dir = self.audio_dir / "tts" / voice_name
        output_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"üìÅ Output directory: {output_dir}")

        # Collecter toutes les objections selon th√©matique
        all_objections = {}

        if theme:
            # Th√©matique sp√©cifique
            objections_list = objections_database.get_objections_by_theme(theme)
            all_objections[theme] = objections_list
            logger.info(f"üìã Theme: {theme}")
        else:
            # Toutes les th√©matiques
            themes = objections_database.get_all_themes()
            for theme_name in themes:
                objections_list = objections_database.get_objections_by_theme(theme_name)
                if objections_list:
                    all_objections[theme_name] = objections_list

            logger.info(f"üìã Themes: {', '.join(all_objections.keys())}")

        # Compter total
        total_count = sum(len(obj_list) for obj_list in all_objections.values())
        logger.info(f"üìä Total objections: {total_count}")

        if total_count == 0:
            logger.warning("‚ö†Ô∏è  No objections found")
            return False

        # Estimer temps (2s par objection environ)
        estimated_time_minutes = (total_count * 2) / 60
        logger.info(f"‚è±Ô∏è  Estimated time: {estimated_time_minutes:.1f} minutes")

        print(f"\n‚ö†Ô∏è  This will generate {total_count} TTS files (~{estimated_time_minutes:.0f} minutes)")
        print(f"   Continue? (y/n): ", end='')

        confirm = input().strip().lower()
        if confirm != 'y':
            logger.info("‚ùå Generation cancelled by user")
            return False

        # G√©n√©rer TTS
        logger.info(f"\nüé§ Generating TTS with voice '{voice_name}'...")

        import time
        start_time = time.time()
        success_count = 0
        failed_count = 0

        for theme_name, objections_list in all_objections.items():
            logger.info(f"\nüìÇ Processing theme: {theme_name.upper()}")
            logger.info(f"   {len(objections_list)} objections")

            for i, objection_entry in enumerate(objections_list, 1):
                # Extraire la r√©ponse (ObjectionEntry ou str)
                if hasattr(objection_entry, 'response'):
                    response_text = objection_entry.response
                elif isinstance(objection_entry, str):
                    response_text = objection_entry
                else:
                    logger.warning(f"   ‚ö†Ô∏è  Skipping invalid entry type: {type(objection_entry)}")
                    continue

                # Cr√©er nom de fichier safe √† partir des premiers mots de la r√©ponse
                # Format: theme_number_debut_reponse.wav
                response_preview = response_text[:30]
                safe_name = self._sanitize_filename(response_preview)
                filename = f"{theme_name}_{i:03d}_{safe_name}.wav"
                output_file = output_dir / filename

                # Skip si existe d√©j√†
                if output_file.exists():
                    logger.debug(f"   ‚è≠Ô∏è  Skip (exists): {filename}")
                    success_count += 1
                    continue

                # G√©n√©rer TTS avec synthesize_with_voice
                try:
                    # Trouver le fichier reference.wav de la voix
                    voice_dir = self.voices_dir / voice_name
                    reference_wav = voice_dir / "reference.wav"

                    if not reference_wav.exists():
                        logger.error(f"   ‚ùå Reference file not found: {reference_wav}")
                        failed_count += 1
                        continue

                    # Utiliser voice_name pour profiter des embeddings cach√©s
                    result_path = self.tts.synthesize_with_voice(
                        text=response_text,
                        reference_voice=str(reference_wav),
                        voice_name=voice_name,  # Utiliser embeddings cach√©s si disponibles
                        output_file=str(output_file)
                    )
                    success = result_path is not None

                    if success:
                        success_count += 1

                        # Log tous les 10 fichiers
                        if success_count % 10 == 0:
                            elapsed = time.time() - start_time
                            rate = success_count / elapsed
                            remaining = (total_count - success_count) / rate if rate > 0 else 0

                            logger.info(f"   ‚úÖ Progress: {success_count}/{total_count} "
                                      f"({success_count*100//total_count}%) - "
                                      f"ETA: {remaining/60:.1f}min")
                    else:
                        failed_count += 1
                        logger.warning(f"   ‚ö†Ô∏è  Failed: {filename}")

                except Exception as e:
                    failed_count += 1
                    logger.error(f"   ‚ùå Error generating {filename}: {e}")

        # Statistiques finales
        elapsed_time = time.time() - start_time

        logger.info(f"\n{'='*60}")
        logger.info(f"‚úÖ TTS Generation completed!")
        logger.info(f"{'='*60}")
        logger.info(f"üìä Statistics:")
        logger.info(f"   Total: {total_count} objections")
        logger.info(f"   Success: {success_count}")
        logger.info(f"   Failed: {failed_count}")
        logger.info(f"   Time: {elapsed_time/60:.1f} minutes")
        logger.info(f"   Rate: {success_count/elapsed_time:.1f} files/sec")
        logger.info(f"üìÅ Output: {output_dir}")

        return success_count > 0

    def _sanitize_filename(self, text: str, max_length: int = 50) -> str:
        """
        Nettoie un texte pour en faire un nom de fichier valide

        Args:
            text: Texte √† nettoyer
            max_length: Longueur max

        Returns:
            Nom de fichier safe
        """
        import re

        # Convertir en minuscules
        safe = text.lower()

        # Remplacer espaces et caract√®res sp√©ciaux par _
        safe = re.sub(r'[^a-z0-9]+', '_', safe)

        # Retirer _ en d√©but/fin
        safe = safe.strip('_')

        # Limiter longueur
        if len(safe) > max_length:
            safe = safe[:max_length]

        return safe


def interactive_select_voice(available_voices: List[str]) -> Optional[str]:
    """
    S√©lection interactive de la voix √† cloner

    Args:
        available_voices: Liste des voix disponibles

    Returns:
        Nom de la voix s√©lectionn√©e ou None
    """
    if not available_voices:
        print("\n‚ùå No voices found in voices/ directory")
        print("üí° Create a folder in voices/ and add audio files (10+ files of 6-10 seconds recommended)")
        return None

    print("\nüìã Available voices:")
    for i, voice in enumerate(available_voices, 1):
        print(f"  {i}. {voice}")

    print(f"\nüé§ Select voice to clone (1-{len(available_voices)}) or 'q' to quit: ", end='')

    choice = input().strip()

    if choice.lower() == 'q':
        return None

    try:
        index = int(choice) - 1
        if 0 <= index < len(available_voices):
            return available_voices[index]
        else:
            print(f"‚ùå Invalid choice: {choice}")
            return None
    except ValueError:
        print(f"‚ùå Invalid input: {choice}")
        return None


def main():
    parser = argparse.ArgumentParser(
        description="Clone voice for TTS (Multi-Voice)",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "--voice",
        help="Voice name to clone (if not specified, interactive mode)"
    )
    parser.add_argument(
        "--skip-tts",
        action="store_true",
        help="Skip TTS generation for objections/FAQ"
    )
    parser.add_argument(
        "--theme",
        help="Theme for TTS generation (finance, crypto, energie, etc.) - default: all themes"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Force overwrite existing voice"
    )
    parser.add_argument(
        "--sequential",
        action="store_true",
        help="Process files sequentially (slower, for debugging)"
    )
    parser.add_argument(
        "--workers",
        type=int,
        default=None,
        help="Number of parallel workers (default: auto-detect CPU cores - 1)"
    )

    args = parser.parse_args()

    print("\n" + "="*60)
    print("üé§  VOICE CLONER - MiniBotPanel v3")
    print("="*60)

    # Initialiser cloner
    cloner = VoiceCloner()

    # D√©tecter voix disponibles
    available_voices = cloner.detect_available_voices()

    # S√©lection voix
    if args.voice:
        voice_name = args.voice
        if voice_name not in available_voices:
            logger.error(f"‚ùå Voice '{voice_name}' not found in voices/")
            logger.info(f"üí° Available voices: {', '.join(available_voices) if available_voices else 'None'}")
            return
    else:
        # Mode interactif
        voice_name = interactive_select_voice(available_voices)
        if not voice_name:
            return

    # Traiter voix
    success = cloner.process_voice_folder(
        voice_name,
        force=args.force,
        sequential=args.sequential,
        num_workers=args.workers
    )

    if not success:
        logger.error("\n‚ùå Voice cloning failed")
        return

    # G√©n√©rer TTS pour objections/FAQ (sauf si skip)
    if not args.skip_tts:
        theme = args.theme if args.theme else None
        tts_success = cloner.generate_tts_for_objections(voice_name, theme=theme)

        if tts_success:
            print("\n" + "="*60)
            print(f"‚úÖ Voice cloning + TTS generation completed!")
            print(f"üìÅ Voice: voices/{voice_name}/")
            print(f"üìÅ TTS files: audio/tts/{voice_name}/")
            print("="*60)
        else:
            print("\n" + "="*60)
            print(f"‚úÖ Voice cloning completed!")
            print(f"‚ö†Ô∏è  TTS generation failed or skipped")
            print(f"üìÅ Voice saved: voices/{voice_name}/")
            print("="*60)
    else:
        print("\n" + "="*60)
        print(f"‚úÖ Voice cloning completed successfully!")
        print(f"üìÅ Voice saved: voices/{voice_name}/")
        print("="*60)


if __name__ == "__main__":
    main()
