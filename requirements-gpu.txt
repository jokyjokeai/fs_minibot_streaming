# MiniBotPanel v3 - Requirements GPU (CUDA 11.8+)
# Python 3.11+ recommandé
# Pour CPU-only, utilisez requirements-cpu.txt

# ============================================
# WEB FRAMEWORK & API
# ============================================
fastapi==0.109.0
uvicorn[standard]==0.27.0
python-multipart==0.0.6
pydantic==2.12.0
pydantic-settings==2.1.0

# ============================================
# DATABASE
# ============================================
sqlalchemy==2.0.25
psycopg2-binary==2.9.11

# ============================================
# AI SERVICES - PyTorch GPU (CUDA 12.1)
# ============================================
--index-url https://download.pytorch.org/whl/cu121
torch==2.5.0
torchaudio==2.5.0
torchvision==0.20.0
--index-url https://pypi.org/simple

numpy==1.26.4
transformers==4.46.3

# NVIDIA cuDNN for GPU acceleration (~665 MB)
# PyTorch 2.5.0 requiert cuDNN 9.1.0.70 (compatible CUDA 12.1)
nvidia-cudnn-cu12==9.1.0.70

# ============================================
# SPEECH-TO-TEXT (Vosk + Faster-Whisper + WhisperStreaming)
# ============================================
vosk==0.3.45  # Fallback CPU-only STT
faster-whisper==1.1.0  # Primary GPU-accelerated STT (3-5x faster)
git+https://github.com/ufal/whisper_streaming  # Vrai streaming chunk-by-chunk (V3)
soundfile==0.12.1
webrtcvad==2.0.10
websockets>=12.0

# ============================================
# NLP (Ollama)
# ============================================
ollama>=0.6.0
requests==2.31.0

# ============================================
# AUDIO PROCESSING
# ============================================
pydub==0.25.1
librosa==0.10.1
scipy==1.11.4

# ============================================
# UTILITIES
# ============================================
python-dotenv==1.1.1
colorama==0.4.6
click==8.1.7
tabulate==0.9.0
openpyxl==3.1.2
phonenumbers==8.13.27
rich==14.2.0  # Colored logs and rich formatting
unidecode==1.3.6  # Unicode normalization (AMD keywords)
rapidfuzz==3.14.3  # Fuzzy matching for intents_db (v3.0)

# ============================================
# NOTES INSTALLATION GPU
# ============================================
# PRÉREQUIS:
# - NVIDIA GPU avec CUDA Compute Capability >= 3.5 (ex: RTX 4090)
# - CUDA 12.1+ installé (https://developer.nvidia.com/cuda-toolkit)
# - cuDNN 9.1.0 (auto-installé par nvidia-cudnn-cu12)
#
# 1. Créer venv Python 3.10+:
#    python3 -m venv venv
#    source venv/bin/activate
#
# 2. Installer dépendances:
#    pip install --upgrade pip setuptools wheel
#    pip install -r requirements-gpu.txt
#
# 3. Vérifier GPU:
#    python -c "import torch; print(f'PyTorch {torch.__version__} - CUDA: {torch.cuda.is_available()} - cuDNN: {torch.backends.cudnn.version()}')"
#
# 4. Créer symlinks cuDNN (requis pour CTranslate2/Faster-Whisper):
#    cd venv/lib/python3.10/site-packages/nvidia/cudnn/lib
#    for lib in libcudnn*.so.9; do ln -sf "$lib" "${lib}.1.0"; done
#
# 5. ESL FreeSWITCH:
#    Compiler depuis sources FreeSWITCH (voir documentation/install_fs_minibot.md)
#
# 6. Modèle Vosk français:
#    wget https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip
#    unzip vosk-model-small-fr-0.22.zip -d models/
#
# 7. Ollama (installer séparément):
#    https://ollama.ai/download
#    ollama pull mistral:7b

# ============================================
# CHANGEMENTS V3.1 (2025) - NETTOYAGE
# ============================================
# SUPPRIMÉ (packages jamais utilisés dans le code):
#   - huggingface-hub → Dépendance transitive de transformers (auto-installé)
#   - safetensors → Dépendance transitive de transformers (auto-installé)
#   - tokenizers → Dépendance transitive de transformers (auto-installé)
#   - TTS (Coqui) → Supprimé v3 (audio pré-enregistré uniquement)
#   - torchvision → Non utilisé dans le projet
#   - alembic → Pas de migrations DB automatiques
#   - prometheus-client → Monitoring non utilisé
#   - python-json-logger → Logging natif Python
#   - pytest/black/flake8 → Tools de dev (non nécessaires en production)
#
# CONSERVÉ (réellement utilisé):
#   - faster-whisper==1.1.0 → GPU-accelerated STT (3-5x faster than Vosk)
#   - whisper-streaming (ufal) → VRAI streaming chunk-by-chunk pour barge-in V3
#   - vosk==0.3.45 → Fallback CPU-only STT robuste
#   - ollama → NLP/Intent classification
#   - websockets → Streaming ASR temps réel
#   - torch/torchaudio CUDA 11.8 → Support GPU pour Faster-Whisper
#   - All web/database/audio packages → Utilisés activement
#
# STT MODES (V3):
#   - Phase AMD (batch): Faster-Whisper 2.3s transcription complète
#   - Phase PLAYING (streaming): WhisperStreaming chunk-by-chunk real-time
#   - Latence streaming: 50-100ms vs 200ms batch périodique
#   Vosk (fallback): CPU-only mais robuste, utilisé si GPU indisponible
