# MiniBotPanel v3 - Requirements GPU (CUDA 11.8+)
# Python 3.11+ recommandé
# Pour CPU-only, utilisez requirements-cpu.txt

# ============================================
# WEB FRAMEWORK & API
# ============================================
fastapi==0.109.0
uvicorn[standard]==0.27.0
python-multipart==0.0.6
pydantic==2.12.0
pydantic-settings==2.1.0

# ============================================
# DATABASE
# ============================================
sqlalchemy==2.0.25
psycopg2-binary==2.9.11

# ============================================
# AI SERVICES - PyTorch GPU (CUDA 11.8)
# ============================================
--index-url https://download.pytorch.org/whl/cu118
torch==2.4.0
torchaudio==2.4.0
--index-url https://pypi.org/simple

numpy==1.26.4
transformers==4.46.3

# ============================================
# SPEECH-TO-TEXT (Vosk + Faster-Whisper)
# ============================================
vosk==0.3.45  # Fallback CPU-only STT
faster-whisper==1.1.0  # Primary GPU-accelerated STT (3-5x faster)
soundfile==0.12.1
webrtcvad==2.0.10
websockets>=12.0

# ============================================
# NLP (Ollama)
# ============================================
ollama>=0.6.0
requests==2.31.0

# ============================================
# AUDIO PROCESSING
# ============================================
pydub==0.25.1
librosa==0.10.1
scipy==1.11.4

# ============================================
# UTILITIES
# ============================================
python-dotenv==1.1.1
colorama==0.4.6
click==8.1.7
tabulate==0.9.0
openpyxl==3.1.2
phonenumbers==8.13.27

# ============================================
# NOTES INSTALLATION GPU
# ============================================
# PRÉREQUIS:
# - NVIDIA GPU avec CUDA Compute Capability >= 3.5
# - CUDA 11.8+ installé (https://developer.nvidia.com/cuda-toolkit)
# - cuDNN 8.x (https://developer.nvidia.com/cudnn)
#
# 1. Créer venv Python 3.11:
#    python3.11 -m venv venv
#    source venv/bin/activate
#
# 2. Installer dépendances:
#    pip install --upgrade pip setuptools wheel
#    pip install -r requirements-gpu.txt
#
# 3. Vérifier GPU:
#    python -c "import torch; print(f'GPU: {torch.cuda.is_available()}')"
#
# 4. ESL FreeSWITCH:
#    Compiler depuis sources FreeSWITCH (voir documentation/install_fs_minibot.md)
#
# 5. Modèle Vosk français:
#    wget https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip
#    unzip vosk-model-small-fr-0.22.zip -d models/
#
# 6. Ollama (installer séparément):
#    https://ollama.ai/download
#    ollama pull mistral:7b

# ============================================
# CHANGEMENTS V3.1 (2025) - NETTOYAGE
# ============================================
# SUPPRIMÉ (packages jamais utilisés dans le code):
#   - huggingface-hub → Dépendance transitive de transformers (auto-installé)
#   - safetensors → Dépendance transitive de transformers (auto-installé)
#   - tokenizers → Dépendance transitive de transformers (auto-installé)
#   - TTS (Coqui) → Supprimé v3 (audio pré-enregistré uniquement)
#   - torchvision → Non utilisé dans le projet
#   - alembic → Pas de migrations DB automatiques
#   - prometheus-client → Monitoring non utilisé
#   - python-json-logger → Logging natif Python
#   - pytest/black/flake8 → Tools de dev (non nécessaires en production)
#
# CONSERVÉ (réellement utilisé):
#   - faster-whisper==1.1.0 → GPU-accelerated STT (3-5x faster than Vosk)
#   - vosk==0.3.45 → Fallback CPU-only STT robuste
#   - ollama → NLP/Intent classification
#   - websockets → Streaming ASR temps réel
#   - torch/torchaudio CUDA 11.8 → Support GPU pour Faster-Whisper
#   - All web/database/audio packages → Utilisés activement
#
# FASTER-WHISPER vs VOSK:
#   Faster-Whisper (primary): GPU-accelerated, 3-5x faster (0.3-0.5s vs 1.5s)
#   Vosk (fallback): CPU-only mais robuste, utilisé si GPU indisponible
#   Changement engine: STT_ENGINE=vosk ou STT_ENGINE=faster_whisper dans .env
